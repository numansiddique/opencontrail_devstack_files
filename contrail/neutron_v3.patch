diff --git neutron/extensions/ipam.py neutron/extensions/ipam.py
new file mode 100644
index 0000000..5d610b3
--- /dev/null
+++ neutron/extensions/ipam.py
@@ -0,0 +1,140 @@
+from abc import abstractmethod
+
+from neutron.api.v2 import attributes as attr
+from neutron.api.v2 import base
+from neutron.common import exceptions as qexception
+from neutron.api import extensions
+from neutron import manager
+from oslo.config import cfg
+
+
+# Ipam Exceptions
+class IpamNotFound(qexception.NotFound):
+    message = _("IPAM %(id)s could not be found")
+
+# Attribute Map
+RESOURCE_ATTRIBUTE_MAP = {
+    'ipams': {
+        'id': {'allow_post': False, 'allow_put': False,
+               'validate': {'type:regex': attr.UUID_PATTERN},
+               'is_visible': True},
+        'name': {'allow_post': True, 'allow_put': False,
+                 'is_visible': True, 'default': ''},
+        'fq_name': {'allow_post': False, 'allow_put': False,
+                    'is_visible': True},
+        'tenant_id': {'allow_post': True, 'allow_put': False,
+                      'required_by_policy': True,
+                      'is_visible': True},
+        'mgmt': {'allow_post': True, 'allow_put': True,
+                 'is_visible': True, 'default': None},
+        'nets_using': {'allow_post': False, 'allow_put': False,
+                       'is_visible': True, 'default': ''}
+    },
+}
+
+# TODO should this be tied to ipam extension?
+EXTENDED_ATTRIBUTES_2_0 = {
+    'networks': {
+        'contrail:fq_name': {'allow_post': False,
+                             'allow_put': False,
+                             'is_visible': True},
+        'contrail:instance_count': {'allow_post': False,
+                                    'allow_put': False,
+                                    'is_visible': True},
+        'contrail:policys': {'allow_post': True,
+                             'allow_put': True,
+                             'default': '',
+                             'is_visible': True},
+        'contrail:subnet_ipam': {'allow_post': False,
+                                 'allow_put': False,
+                                 'default': '',
+                                 'is_visible': True},
+    },
+    'subnets': {
+        'contrail:instance_count': {'allow_post': False,
+                                    'allow_put': False,
+                                    'is_visible': True},
+        'contrail:ipam_fq_name': {'allow_post': True,
+                                  'allow_put': True,
+                                  'default': '',
+                                  'is_visible': True},
+    }
+}
+
+
+class Ipam(object):
+
+    @classmethod
+    def get_name(cls):
+        return "Network IP Address Management"
+
+    @classmethod
+    def get_alias(cls):
+        return "ipam"
+
+    @classmethod
+    def get_description(cls):
+        return ("Configuration object for holding common to a set of"
+                " IP address blocks")
+
+    @classmethod
+    def get_namespace(cls):
+        return "http://docs.openstack.org/TODO"
+
+    @classmethod
+    def get_updated(cls):
+        return "2012-07-20T10:00:00-00:00"
+
+    @classmethod
+    def get_resources(cls):
+        """ Returns Ext Resources """
+        exts = []
+        plugin = manager.QuantumManager.get_plugin()
+        for resource_name in ['ipam']:
+            collection_name = resource_name + "s"
+            params = RESOURCE_ATTRIBUTE_MAP.get(collection_name, dict())
+
+            member_actions = {}
+
+            controller = base.create_resource(collection_name,
+                                              resource_name,
+                                              plugin, params,
+                                              member_actions=member_actions)
+
+            ex = extensions.ResourceExtension(collection_name,
+                                              controller,
+                                              member_actions=member_actions)
+            exts.append(ex)
+
+        return exts
+
+    def get_extended_resources(self, version):
+        if version == "2.0":
+            return EXTENDED_ATTRIBUTES_2_0
+        else:
+            return {}
+#end class Ipam
+
+
+class IpamPluginBase(object):
+
+    @abstractmethod
+    def create_ipam(self, context, ipam):
+        pass
+
+    @abstractmethod
+    def update_ipam(self, context, id, ipam):
+        pass
+
+    @abstractmethod
+    def get_ipam(self, context, id, fields=None):
+        pass
+
+    @abstractmethod
+    def delete_ipam(self, context, id):
+        pass
+
+    @abstractmethod
+    def get_ipams(self, context, filters=None, fields=None):
+        pass
+#end class IpamPluginBase
diff --git neutron/extensions/portbindings.py neutron/extensions/portbindings.py
index dbef592..f6b2144 100644
--- neutron/extensions/portbindings.py
+++ neutron/extensions/portbindings.py
@@ -45,11 +45,12 @@ VIF_TYPE_802_QBG = '802.1qbg'
 VIF_TYPE_802_QBH = '802.1qbh'
 VIF_TYPE_HYPERV = 'hyperv'
 VIF_TYPE_MIDONET = 'midonet'
+VIF_TYPE_CONTRAIL = 'contrail'
 VIF_TYPE_OTHER = 'other'
 VIF_TYPES = [VIF_TYPE_UNBOUND, VIF_TYPE_BINDING_FAILED, VIF_TYPE_OVS,
              VIF_TYPE_IVS, VIF_TYPE_BRIDGE, VIF_TYPE_802_QBG,
              VIF_TYPE_802_QBH, VIF_TYPE_HYPERV, VIF_TYPE_MIDONET,
-             VIF_TYPE_OTHER]
+             VIF_TYPE_CONTRAIL, VIF_TYPE_OTHER]
 
 
 EXTENDED_ATTRIBUTES_2_0 = {
diff --git neutron/plugins/juniper/__init__.py neutron/plugins/juniper/__init__.py
new file mode 100644
index 0000000..7bc8217
--- /dev/null
+++ neutron/plugins/juniper/__init__.py
@@ -0,0 +1,17 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+#
+# Copyright 2013 Juniper Networks.  All rights reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+#
+# @author: Hampapur Ajay Juniper Networks.
diff --git neutron/plugins/juniper/contrail/__init__.py neutron/plugins/juniper/contrail/__init__.py
new file mode 100644
index 0000000..7bc8217
--- /dev/null
+++ neutron/plugins/juniper/contrail/__init__.py
@@ -0,0 +1,17 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+#
+# Copyright 2013 Juniper Networks.  All rights reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+#
+# @author: Hampapur Ajay Juniper Networks.
diff --git neutron/plugins/juniper/contrail/contrailplugin.py neutron/plugins/juniper/contrail/contrailplugin.py
new file mode 100644
index 0000000..8028b32
--- /dev/null
+++ neutron/plugins/juniper/contrail/contrailplugin.py
@@ -0,0 +1,1187 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+#
+# Copyright 2013 Juniper Networks.  All rights reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+#
+# @author: Hampapur Ajay, Rudra Rugge, Atul Moghe Juniper Networks.
+
+
+import ConfigParser
+import logging
+from pprint import pformat
+
+#from neutron.manager import NeutronManager
+from neutron.common import exceptions as exc
+from neutron.db import db_base_plugin_v2
+from neutron.db import portbindings_base
+from neutron.extensions import l3
+from neutron.extensions import securitygroup
+from neutron.extensions import portbindings
+#from neutron.extensions import vpcroutetable
+
+import cgitb
+from httplib2 import Http
+from oslo.config import cfg
+import re
+import string
+import sys
+
+import ctdb.config_db
+
+LOG = logging.getLogger(__name__)
+
+vnc_opts = [
+    cfg.StrOpt('api_server_ip', default='127.0.0.1'),
+    cfg.StrOpt('api_server_port', default='8082'),
+]
+
+
+def _read_cfg(cfg_parser, section, option, default):
+        try:
+            val = cfg_parser.get(section, option)
+        except (AttributeError,
+                ConfigParser.NoOptionError,
+                ConfigParser.NoSectionError):
+            val = default
+
+        return val
+
+
+def _read_cfg_boolean(cfg_parser, section, option, default):
+        try:
+            val = cfg_parser.getboolean(section, option)
+        except (AttributeError, ValueError,
+                ConfigParser.NoOptionError,
+                ConfigParser.NoSectionError):
+            val = default
+
+        return val
+
+
+class ContrailPlugin(db_base_plugin_v2.NeutronDbPluginV2,
+                     l3.RouterPluginBase,
+                     securitygroup.SecurityGroupPluginBase,
+                     portbindings_base.PortBindingBaseMixin):
+#vpcroutetable.RouteTablePluginBase):
+
+    supported_extension_aliases = ["ipam", "policy", "security-group",
+                                   "router", "route-table", "port-security",
+                                   "binding",]
+    __native_bulk_support = False
+    _cfgdb = None
+    _args = None
+    _tenant_id_dict = {}
+    _tenant_name_dict = {}
+
+    @classmethod
+    def _parse_class_args(cls, cfg_parser):
+        cfg_parser.read("/etc/neutron/plugins/juniper/"
+                        "contrail/ContrailPlugin.ini"
+                        )
+        cls._multi_tenancy = _read_cfg_boolean(cfg_parser, 'APISERVER',
+                                               'multi_tenancy', False)
+        cls._admin_token = _read_cfg(cfg_parser, 'KEYSTONE', 'admin_token', '')
+        cls._auth_url = _read_cfg(cfg_parser, 'KEYSTONE', 'auth_url', '')
+        cls._admin_user = _read_cfg(cfg_parser, 'KEYSTONE', 'admin_user',
+                                    'user1')
+        cls._admin_password = _read_cfg(cfg_parser, 'KEYSTONE',
+                                        'admin_password', 'password1')
+        cls._admin_tenant_name = _read_cfg(cfg_parser, 'KEYSTONE',
+                                           'admin_tenant_name',
+                                           'default-domain')
+        cls._tenants_api = '%s/tenants' % (cls._auth_url)
+        pass
+
+    @classmethod
+    def _connect_to_db(cls):
+        """
+        Many instantiations of plugin (base + extensions) but need to have
+    only one config db conn (else error from ifmap-server)
+    """
+        cls._cfgdb_map = {}
+        if cls._cfgdb is None:
+            sip = cfg.CONF.APISERVER.api_server_ip
+            sport = cfg.CONF.APISERVER.api_server_port
+            # Initialize connection to DB and add default entries
+            cls._cfgdb = ctdb.config_db.DBInterface(cls._admin_user,
+                                                    cls._admin_password,
+                                                    cls._admin_tenant_name,
+                                                    sip, sport)
+            cls._cfgdb.manager = cls
+
+    @classmethod
+    def _get_user_cfgdb(cls, context):
+        if not cls._multi_tenancy:
+            return cls._cfgdb
+        user_id = context.user_id
+        role = string.join(context.roles, ",")
+        if user_id not in cls._cfgdb_map:
+            cls._cfgdb_map[user_id] = ctdb.config_db.DBInterface(
+                cls._admin_user, cls._admin_password, cls._admin_tenant_name,
+                cfg.CONF.APISERVER.api_server_ip,
+                cfg.CONF.APISERVER.api_server_port,
+                user_info={'user_id': user_id, 'role': role})
+            cls._cfgdb_map[user_id].manager = cls
+
+        return cls._cfgdb_map[user_id]
+
+    @classmethod
+    def _tenant_list_from_keystone(cls):
+        # get all tenants
+        hdrs = {'X-Auth-Token': cls._admin_token,
+                'Content-Type': 'application/json'}
+        try:
+            rsp, content = Http().request(cls._tenants_api,
+                                          method="GET", headers=hdrs)
+            if rsp.status != 200:
+                return
+        except Exception:
+            return
+
+        # transform needed for python compatibility
+        content = re.sub('true', 'True', content)
+        content = re.sub('null', 'None', content)
+        content = eval(content)
+
+        # bail if response is unexpected
+        if 'tenants' not in content:
+            return
+
+        # create a dictionary for id->name and name->id mapping
+        for tenant in content['tenants']:
+            print 'Adding tenant %s:%s to cache' % (tenant['name'],
+                                                    tenant['id'])
+            cls._tenant_id_dict[tenant['id']] = tenant['name']
+            cls._tenant_name_dict[tenant['name']] = tenant['id']
+
+    def update_security_group(self, context, id, security_group):
+        pass
+
+    def __init__(self):
+        cfg.CONF.register_opts(vnc_opts, 'APISERVER')
+
+        cfg_parser = ConfigParser.ConfigParser()
+        ContrailPlugin._parse_class_args(cfg_parser)
+
+        ContrailPlugin._connect_to_db()
+        self._cfgdb = ContrailPlugin._cfgdb
+
+        ContrailPlugin._tenant_list_from_keystone()
+        self.base_binding_dict = self._get_base_binding_dict()
+        portbindings_base.register_port_dict_function()
+
+    def _get_base_binding_dict(self):
+        binding = {
+            portbindings.VIF_TYPE: portbindings.VIF_TYPE_CONTRAIL,
+            portbindings.CAPABILITIES: {
+                portbindings.CAP_PORT_FILTER:
+                'security-group' in self.supported_extension_aliases}}
+        return binding
+
+    @classmethod
+    def tenant_id_to_name(cls, id):
+        # bail if we never built the list successfully
+        if len(cls._tenant_id_dict) == 0:
+            return id
+        # check cache
+        if id in cls._tenant_id_dict:
+            return cls._tenant_id_dict[id]
+        # otherwise refresh
+        cls._tenant_list_from_keystone()
+        # second time's a charm?
+        return cls._tenant_id_dict[id] if id in cls._tenant_id_dict else id
+
+    @classmethod
+    def tenant_name_to_id(cls, name):
+        # bail if we never built the list successfully
+        if len(cls._tenant_name_dict) == 0:
+            return name
+        # check cache
+        if name in cls._tenant_name_dict:
+            return cls._tenant_name_dict[name]
+        # otherwise refresh
+        cls._tenant_list_from_keystone()
+        # second time's a charm?
+        if name in cls._tenant_name_dict:
+            return cls._tenant_name_dict[name]
+        else:
+            return name
+
+    # Network API handlers
+    def create_network(self, context, network):
+        """
+        Creates a new Virtual Network, and assigns it
+        a symbolic name.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            net_info = cfgdb.network_create(network['network'])
+
+            # verify transformation is conforming to api
+            net_dict = self._make_network_dict(net_info['q_api_data'],
+                                               None, False)
+
+            net_dict.update(net_info['q_extra_data'])
+
+            LOG.debug("create_network(): " + pformat(net_dict) + "\n")
+            return net_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_network(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            net_info = cfgdb.network_read(id, fields)
+
+            # verify transformation is conforming to api
+            if not fields:
+                # should return all fields
+                net_dict = self._make_network_dict(net_info['q_api_data'],
+                                                   fields, False)
+                net_dict.update(net_info['q_extra_data'])
+            else:
+                net_dict = net_info['q_api_data']
+
+            LOG.debug("get_network(): " + pformat(net_dict))
+            return self._fields(net_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_network(self, context, net_id, network):
+        """
+        Updates the attributes of a particular Virtual Network.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            net_info = cfgdb.network_update(net_id, network['network'])
+
+            # verify transformation is conforming to api
+            net_dict = self._make_network_dict(net_info['q_api_data'],
+                                               None, False)
+
+            net_dict.update(net_info['q_extra_data'])
+
+            LOG.debug("update_network(): " + pformat(net_dict))
+            return net_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_network(self, context, net_id):
+        """
+        Deletes the network with the specified network identifier
+        belonging to the specified tenant.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.network_delete(net_id)
+            LOG.debug("delete_network(): " + pformat(net_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_networks(self, context, filters=None, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            nets_info = cfgdb.network_list(filters)
+
+            nets_dicts = []
+            for n_info in nets_info:
+                # verify transformation is conforming to api
+                n_dict = self._make_network_dict(n_info['q_api_data'], fields,
+                                                 False)
+
+                n_dict.update(n_info['q_extra_data'])
+                nets_dicts.append(n_dict)
+
+            LOG.debug(
+                "get_networks(): filters: " + pformat(filters) + " data: "
+                + pformat(nets_dicts))
+            return nets_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_networks_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            nets_count = cfgdb.network_count(filters)
+            LOG.debug("get_networks_count(): " + str(nets_count))
+            return nets_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Subnet API handlers
+    def create_subnet(self, context, subnet):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            subnet_info = cfgdb.subnet_create(subnet['subnet'])
+
+            # verify transformation is conforming to api
+            subnet_dict = self._make_subnet_dict(subnet_info['q_api_data'])
+
+            subnet_dict.update(subnet_info['q_extra_data'])
+
+            LOG.debug("create_subnet(): " + pformat(subnet_dict))
+            return subnet_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_subnet(self, context, subnet_id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            subnet_info = cfgdb.subnet_read(subnet_id)
+
+            # verify transformation is conforming to api
+            subnet_dict = self._make_subnet_dict(subnet_info['q_api_data'],
+                                                 fields)
+
+            subnet_dict.update(subnet_info['q_extra_data'])
+
+            LOG.debug("get_subnet(): " + pformat(subnet_dict))
+            return self._fields(subnet_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_subnet(self, context, subnet_id, subnet):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            subnet_info = cfgdb.subnet_update(subnet_id, subnet['subnet'])
+
+            # verify transformation is conforming to api
+            subnet_dict = self._make_subnet_dict(subnet_info['q_api_data'])
+
+            subnet_dict.update(subnet_info['q_extra_data'])
+
+            LOG.debug("update_subnet(): " + pformat(subnet_dict))
+            return subnet_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_subnet(self, context, subnet_id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.subnet_delete(subnet_id)
+
+            LOG.debug("delete_subnet(): " + pformat(subnet_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_subnets(self, context, filters=None, fields=None):
+        """
+        Called from Neutron API -> get_<resource>
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            subnets_info = cfgdb.subnets_list(filters)
+
+            subnets_dicts = []
+            for sn_info in subnets_info:
+                # verify transformation is conforming to api
+                sn_dict = self._make_subnet_dict(sn_info['q_api_data'], fields)
+
+                sn_dict.update(sn_info['q_extra_data'])
+                subnets_dicts.append(sn_dict)
+
+            LOG.debug(
+                "get_subnets(): filters: " + pformat(filters) + " data: "
+                + pformat(subnets_dicts))
+            return subnets_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_subnets_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            subnets_count = cfgdb.subnets_count(filters)
+            LOG.debug("get_subnets_count(): " + str(subnets_count))
+            return subnets_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Ipam API handlers
+    def create_ipam(self, context, ipam):
+        """
+        Creates a new IPAM, and assigns it
+        a symbolic name.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ipam_info = cfgdb.ipam_create(ipam['ipam'])
+
+            ##verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            ipam_dict = ipam_info['q_api_data']
+            ipam_dict.update(ipam_info['q_extra_data'])
+
+            LOG.debug("create_ipam(): " + pformat(ipam_dict))
+            return ipam_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_ipam(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ipam_info = cfgdb.ipam_read(id)
+
+            ## verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            ipam_dict = ipam_info['q_api_data']
+            ipam_dict.update(ipam_info['q_extra_data'])
+
+            LOG.debug("get_ipam(): " + pformat(ipam_dict))
+            return ipam_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_ipam(self, context, id, ipam):
+        """
+        Updates the attributes of a particular IPAM.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ipam_info = cfgdb.ipam_update(id, ipam)
+
+            ## verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            ipam_dict = ipam_info['q_api_data']
+            ipam_dict.update(ipam_info['q_extra_data'])
+
+            LOG.debug("update_ipam(): " + pformat(ipam_dict))
+            return ipam_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_ipam(self, context, ipam_id):
+        """
+        Deletes the ipam with the specified identifier
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.ipam_delete(ipam_id)
+
+            LOG.debug("delete_ipam(): " + pformat(ipam_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_ipams(self, context, filters=None, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ipams_info = cfgdb.ipam_list(filters)
+
+            ipams_dicts = []
+            for ipam_info in ipams_info:
+                # verify transformation is conforming to api
+                #ipam_dict = self._make_ipam_dict(ipam_info)
+                ipam_dict = ipam_info['q_api_data']
+                ipam_dict.update(ipam_info['q_extra_data'])
+                ipams_dicts.append(ipam_dict)
+
+            LOG.debug("get_ipams(): " + pformat(ipams_dicts))
+            return ipams_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_ipams_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ipams_count = cfgdb.ipams_count(filters)
+            LOG.debug("get_ipams_count(): " + str(ipams_count))
+            return ipams_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Policy API handlers
+    def create_policy(self, context, policy):
+        """
+        Creates a new Policy, and assigns it
+        a symbolic name.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            policy_info = cfgdb.policy_create(policy['policy'])
+
+            ##verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            policy_dict = policy_info['q_api_data']
+            policy_dict.update(policy_info['q_extra_data'])
+
+            LOG.debug("create_policy(): " + pformat(policy_dict))
+            return policy_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_policy(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            policy_info = cfgdb.policy_read(id)
+
+            ## verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            policy_dict = policy_info['q_api_data']
+            policy_dict.update(policy_info['q_extra_data'])
+
+            LOG.debug("get_policy(): " + pformat(policy_dict))
+            return policy_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_policy(self, context, id, policy):
+        """
+        Updates the attributes of a particular Policy.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            policy_info = cfgdb.policy_update(id, policy)
+
+            ## verify transformation is conforming to api
+            #ipam_dict = self._make_ipam_dict(ipam_info)
+            policy_dict = policy_info['q_api_data']
+            policy_dict.update(policy_info['q_extra_data'])
+
+            LOG.debug("update_policy(): " + pformat(policy_dict))
+            return policy_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_policy(self, context, policy_id):
+        """
+        Deletes the Policy with the specified identifier
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.policy_delete(policy_id)
+
+            LOG.debug("delete_policy(): " + pformat(policy_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_policys(self, context, filters=None, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            policys_info = cfgdb.policy_list(filters)
+
+            policys_dicts = []
+            for policy_info in policys_info:
+                # verify transformation is conforming to api
+                #ipam_dict = self._make_ipam_dict(ipam_info)
+                policy_dict = policy_info['q_api_data']
+                policy_dict.update(policy_info['q_extra_data'])
+                policys_dicts.append(policy_dict)
+
+            LOG.debug("get_policys(): " + pformat(policys_dicts))
+            return policys_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_policy_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            policy_count = cfgdb.policy_count(filters)
+            LOG.debug("get_policy_count(): " + str(policy_count))
+            return policy_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Floating IP API handlers
+    def _make_floatingip_dict(self, floatingip, fields=None):
+        res = {'id': floatingip['id'],
+               'tenant_id': floatingip['tenant_id'],
+               'floating_ip_address': floatingip['floating_ip_address'],
+               'floating_network_id': floatingip['floating_network_id'],
+               'router_id': floatingip['router_id'],
+               'port_id': floatingip['fixed_port_id'],
+               'fixed_ip_address': floatingip['fixed_ip_address']}
+        return self._fields(res, fields)
+
+    def create_floatingip(self, context, floatingip):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            fip_info = cfgdb.floatingip_create(floatingip['floatingip'])
+
+            # verify transformation is conforming to api
+            fip_dict = self._make_floatingip_dict(fip_info['q_api_data'])
+
+            fip_dict.update(fip_info['q_extra_data'])
+
+            LOG.debug("create_floatingip(): " + pformat(fip_dict))
+            return fip_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_floatingip(self, context, fip_id, floatingip):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            fip_info = cfgdb.floatingip_update(fip_id,
+                                               floatingip['floatingip'])
+
+            # verify transformation is conforming to api
+            fip_dict = self._make_floatingip_dict(fip_info['q_api_data'])
+
+            fip_dict.update(fip_info['q_extra_data'])
+
+            LOG.debug("update_floatingip(): " + pformat(fip_dict))
+            return fip_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_floatingip(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            fip_info = cfgdb.floatingip_read(id)
+
+            # verify transformation is conforming to api
+            fip_dict = self._make_floatingip_dict(fip_info['q_api_data'])
+
+            fip_dict.update(fip_info['q_extra_data'])
+
+            LOG.debug("get_floatingip(): " + pformat(fip_dict))
+            return fip_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_floatingip(self, context, fip_id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.floatingip_delete(fip_id)
+            LOG.debug("delete_floating(): " + pformat(fip_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_floatingips(self, context, filters=None, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            fips_info = cfgdb.floatingip_list(filters)
+
+            fips_dicts = []
+            for fip_info in fips_info:
+                # verify transformation is conforming to api
+                fip_dict = self._make_floatingip_dict(fip_info['q_api_data'])
+
+                fip_dict.update(fip_info['q_extra_data'])
+                fips_dicts.append(fip_dict)
+
+            LOG.debug("get_floatingips(): " + pformat(fips_dicts))
+            return fips_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_floatingips_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            floatingips_count = cfgdb.floatingip_count(filters)
+            LOG.debug("get_floatingips_count(): " + str(floatingips_count))
+            return floatingips_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Port API handlers
+    def create_port(self, context, port):
+        """
+        Creates a port on the specified Virtual Network.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            port_info = cfgdb.port_create(port['port'])
+
+            # verify transformation is conforming to api
+            port_dict = self._make_port_dict(port_info['q_api_data'])
+            self._process_portbindings_create_and_update(context,
+                                                         port['port'],
+                                                         port_dict)
+
+            port_dict.update(port_info['q_extra_data'])
+
+
+            LOG.debug("create_port(): " + pformat(port_dict))
+            return port_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_port(self, context, port_id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            port_info = cfgdb.port_read(port_id)
+
+            # verify transformation is conforming to api
+            port_dict = self._make_port_dict(port_info['q_api_data'], fields)
+            self._process_portbindings_create_and_update(context,
+                                                         port_info,
+                                                         port_dict)
+
+            port_dict.update(port_info['q_extra_data'])
+
+            LOG.debug("get_port(): " + pformat(port_dict))
+            return self._fields(port_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_port(self, context, port_id, port):
+        """
+        Updates the attributes of a port on the specified Virtual Network.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            port_info = cfgdb.port_update(port_id, port['port'])
+
+            # verify transformation is conforming to api
+            port_dict = self._make_port_dict(port_info['q_api_data'])
+            self._process_portbindings_create_and_update(context,
+                                                         port['port'],
+                                                         port_dict)
+
+            port_dict.update(port_info['q_extra_data'])
+
+            LOG.debug("update_port(): " + pformat(port_dict))
+            return port_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_port(self, context, port_id):
+        """
+        Deletes a port on a specified Virtual Network,
+        if the port contains a remote interface attachment,
+        the remote interface is first un-plugged and then the port
+        is deleted.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.port_delete(port_id)
+            LOG.debug("delete_port(): " + pformat(port_id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_ports(self, context, filters=None, fields=None):
+        """
+        Retrieves all port identifiers belonging to the
+        specified Virtual Network.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ports_info = cfgdb.port_list(filters)
+
+            ports_dicts = []
+            for p_info in ports_info:
+                # verify transformation is conforming to api
+                p_dict = self._make_port_dict(p_info['q_api_data'], fields)
+            	self._process_portbindings_create_and_update(context,
+                                                         p_info,
+                                                         p_dict)
+
+                p_dict.update(p_info['q_extra_data'])
+                ports_dicts.append(p_dict)
+
+            LOG.debug(
+                "get_ports(): filter: " + pformat(filters) + 'data: '
+                + pformat(ports_dicts))
+            return ports_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_ports_count(self, context, filters=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            ports_count = cfgdb.port_count(filters)
+            LOG.debug("get_ports_count(): " + str(ports_count))
+            return ports_count
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def plug_interface(self, tenant_id, net_id, port_id, remote_interface_id):
+        """
+        Attaches a remote interface to the specified port on the
+        specified Virtual Network.
+        """
+        port = self._get_port(tenant_id, net_id, port_id)
+        # Validate attachment
+        self._validate_attachment(tenant_id, net_id, port_id,
+                                  remote_interface_id)
+        if port['interface_id']:
+            raise exc.PortInUse(net_id=net_id, port_id=port_id,
+                                att_id=port['interface_id'])
+
+    def unplug_interface(self, tenant_id, net_id, port_id):
+        """
+        Detaches a remote interface from the specified port on the
+        specified Virtual Network.
+        """
+        self._get_port(tenant_id, net_id, port_id)
+
+    # VPC route table handlers
+    def _make_route_table_routes_dict(self, route_table_route, fields=None):
+        res = {'prefix': route_table_route['prefix'],
+               'next_hop': route_table_route['next_hop']}
+
+        return self._fields(res, fields)
+
+    def _make_route_table_dict(self, route_table, fields=None):
+        res = {'id': route_table['id'],
+               'name': route_table['name'],
+               'fq_name': route_table['fq_name'],
+               'tenant_id': route_table['tenant_id']}
+        if route_table['routes']:
+            res['routes'] = [self._make_route_table_routes_dict(r)
+                             for r in route_table['routes']['route']]
+        return self._fields(res, fields)
+
+    def create_route_table(self, context, route_table):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            rt_info = cfgdb.route_table_create(
+                route_table['route_table'])
+
+            # verify transformation is conforming to api
+            rt_dict = self._make_route_table_dict(rt_info['q_api_data'])
+            rt_dict.update(rt_info['q_extra_data'])
+            LOG.debug("create_route_table(): " + pformat(rt_dict))
+            return rt_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def update_route_table(self, context, id, route_table):
+        """
+        Updates the attributes of a particular route table.
+        """
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            rt_info = cfgdb.route_table_update(id, route_table['route_table'])
+
+            rt_dict = self._make_route_table_dict(rt_info['q_api_data'])
+            rt_dict.update(rt_info['q_extra_data'])
+            LOG.debug("create_route_table(): " + pformat(rt_dict))
+            return rt_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_route_table(self, context, id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.route_table_delete(id)
+            LOG.debug("delete_route_table(): " + pformat(id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_route_tables(self, context, filters=None, fields=None,
+                         sorts=None, limit=None, marker=None,
+                         page_reverse=False):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            route_tables_info = cfgdb.route_table_list(context, filters)
+
+            route_tables_dicts = []
+            for rt_info in route_tables_info:
+                # verify transformation is conforming to api
+                rt_dict = self._make_route_table_dict(rt_info['q_api_data'],
+                                                      fields)
+
+                rt_dict.update(rt_info['q_extra_data'])
+                route_tables_dicts.append(rt_dict)
+
+            LOG.debug(
+                "get_route_tables(): filter: " + pformat(filters)
+                + 'data: ' + pformat(route_tables_dicts))
+            return route_tables_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_route_table(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            rt_info = cfgdb.route_table_read(id)
+
+            # verify transformation is conforming to api
+            rt_dict = self._make_route_table_dict(rt_info['q_api_data'],
+                                                  fields)
+
+            rt_dict.update(rt_info['q_extra_data'])
+
+            LOG.debug("get_route_table(): " + pformat(rt_dict))
+            return self._fields(rt_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # VPC route table svc instance handlers
+    def _make_svc_instance_dict(self, svc_instance, fields=None):
+        res = {'id': svc_instance['id'],
+               'name': svc_instance['name'],
+               'tenant_id': svc_instance['tenant_id']}
+        if svc_instance['internal_net']:
+            res['internal_net'] = svc_instance['internal_net']
+        if svc_instance['external_net']:
+            res['external_net'] = svc_instance['external_net']
+        return self._fields(res, fields)
+
+    def create_nat_instance(self, context, nat_instance):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            si_info = cfgdb.svc_instance_create(
+                nat_instance['nat_instance'])
+
+            # verify transformation is conforming to api
+            si_dict = self._make_svc_instance_dict(si_info['q_api_data'])
+
+            si_dict.update(si_info['q_extra_data'])
+
+            LOG.debug("create_nat_instance(): " + pformat(si_dict))
+            return si_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_nat_instance(self, context, id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.svc_instance_delete(id)
+            LOG.debug("delete_nat_instance(): " + pformat(id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_nat_instances(self, context, filters=None, fields=None,
+                          sorts=None, limit=None, marker=None,
+                          page_reverse=False):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            svc_instances_info = cfgdb.svc_instance_list(context, filters)
+
+            svc_instances_dicts = []
+            for si_info in svc_instances_info:
+                # verify transformation is conforming to api
+                si_dict = self._make_svc_instance_dict(si_info['q_api_data'],
+                                                       fields)
+
+                si_dict.update(si_info['q_extra_data'])
+                svc_instances_dicts.append(si_dict)
+
+            LOG.debug(
+                "get_nat_instances(): filter: " + pformat(filters)
+                + 'data: ' + pformat(svc_instances_dicts))
+            return svc_instances_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_nat_instance(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            si_info = cfgdb.svc_instance_read(id)
+
+            # verify transformation is conforming to api
+            si_dict = self._make_svc_instance_dict(si_info['q_api_data'],
+                                                   fields)
+
+            si_dict.update(si_info['q_extra_data'])
+
+            LOG.debug("get_nat_instance(): " + pformat(si_dict))
+            return self._fields(si_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    # Security Group handlers
+    def _make_security_group_rule_dict(self, security_group_rule, fields=None):
+        res = {'id': security_group_rule['id'],
+               'tenant_id': security_group_rule['tenant_id'],
+               'security_group_id': security_group_rule['security_group_id'],
+               'ethertype': security_group_rule['ethertype'],
+               'direction': security_group_rule['direction'],
+               'protocol': security_group_rule['protocol'],
+               'port_range_min': security_group_rule['port_range_min'],
+               'port_range_max': security_group_rule['port_range_max'],
+               'remote_ip_prefix': security_group_rule['remote_ip_prefix'],
+               'remote_group_id': security_group_rule['remote_group_id']}
+
+        return self._fields(res, fields)
+
+    def _make_security_group_dict(self, security_group, fields=None):
+        res = {'id': security_group['id'],
+               'name': security_group['name'],
+               'tenant_id': security_group['tenant_id'],
+               'description': security_group['description']}
+        res['security_group_rules'] = [self._make_security_group_rule_dict(r)
+                                       for r in security_group['rules']]
+        return self._fields(res, fields)
+
+    def create_security_group(self, context, security_group):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            sg_info = cfgdb.security_group_create(
+                security_group['security_group'])
+
+            # verify transformation is conforming to api
+            sg_dict = self._make_security_group_dict(sg_info['q_api_data'])
+
+            sg_dict.update(sg_info['q_extra_data'])
+
+            LOG.debug("create_security_group(): " + pformat(sg_dict))
+            return sg_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_security_group(self, context, id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.security_group_delete(id)
+            LOG.debug("delete_security_group(): " + pformat(id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_security_groups(self, context, filters=None, fields=None,
+                            sorts=None, limit=None, marker=None,
+                            page_reverse=False):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            security_groups_info = cfgdb.security_group_list(context, filters)
+
+            security_groups_dicts = []
+            for sg_info in security_groups_info:
+                # verify transformation is conforming to api
+                sg_dict = self._make_security_group_dict(sg_info['q_api_data'],
+                                                         fields)
+
+                sg_dict.update(sg_info['q_extra_data'])
+                security_groups_dicts.append(sg_dict)
+
+            LOG.debug(
+                "get_security_groups(): filter: " + pformat(filters)
+                + 'data: ' + pformat(security_groups_dicts))
+            return security_groups_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_security_group(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            sg_info = cfgdb.security_group_read(id)
+
+            # verify transformation is conforming to api
+            sg_dict = self._make_security_group_dict(sg_info['q_api_data'],
+                                                     fields)
+
+            sg_dict.update(sg_info['q_extra_data'])
+
+            LOG.debug("get_security_group(): " + pformat(sg_dict))
+            return self._fields(sg_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def create_security_group_rule(self, context, security_group_rule):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            sgr_info = cfgdb.security_group_rule_create(
+                security_group_rule['security_group_rule'])
+
+            # verify transformation is conforming to api
+            sgr_dict = self._make_security_group_rule_dict(
+                sgr_info['q_api_data'])
+            sgr_dict.update(sgr_info['q_extra_data'])
+
+            LOG.debug("create_security_group_rule(): " + pformat(sgr_dict))
+            return sgr_dict
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def delete_security_group_rule(self, context, id):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            cfgdb.security_group_rule_delete(id)
+            LOG.debug("delete_security_group_rule(): " + pformat(id))
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_security_group_rules(self, context, filters=None, fields=None,
+                                 sorts=None, limit=None, marker=None,
+                                 page_reverse=False):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            security_group_rules_info = cfgdb.security_group_rule_list(filters)
+
+            security_group_rules_dicts = []
+            for sgr_info in security_group_rules_info:
+                for sgr in sgr_info:
+                    # verify transformation is conforming to api
+                    sgr_dict = self._make_security_group_rule_dict(
+                        sgr['q_api_data'], fields)
+                    sgr_dict.update(sgr['q_extra_data'])
+                    security_group_rules_dicts.append(sgr_dict)
+
+            LOG.debug(
+                "get_security_group_rules(): filter: " + pformat(filters) +
+                'data: ' + pformat(security_group_rules_dicts))
+            return security_group_rules_dicts
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
+
+    def get_security_group_rule(self, context, id, fields=None):
+        try:
+            cfgdb = ContrailPlugin._get_user_cfgdb(context)
+            sgr_info = cfgdb.security_group_rule_read(id)
+
+            # verify transformation is conforming to api
+            sgr_dict = {}
+            if sgr_info != {}:
+                sgr_dict = self._make_security_group_rule_dict(
+                    sgr_info['q_api_data'], fields)
+                sgr_dict.update(sgr_info['q_extra_data'])
+
+            LOG.debug("get_security_group_rule(): " + pformat(sgr_dict))
+            return self._fields(sgr_dict, fields)
+        except Exception as e:
+            cgitb.Hook(format="text").handle(sys.exc_info())
+            raise e
diff --git neutron/plugins/juniper/contrail/ctdb/__init__.py neutron/plugins/juniper/contrail/ctdb/__init__.py
new file mode 100644
index 0000000..7bc8217
--- /dev/null
+++ neutron/plugins/juniper/contrail/ctdb/__init__.py
@@ -0,0 +1,17 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+#
+# Copyright 2013 Juniper Networks.  All rights reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+#
+# @author: Hampapur Ajay Juniper Networks.
diff --git neutron/plugins/juniper/contrail/ctdb/config_db.py neutron/plugins/juniper/contrail/ctdb/config_db.py
new file mode 100644
index 0000000..4a87a41
--- /dev/null
+++ neutron/plugins/juniper/contrail/ctdb/config_db.py
@@ -0,0 +1,2238 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+#
+# Copyright 2013 Juniper Networks.  All rights reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+#
+# @author: Hampapur Ajay, Rudra Rugge, Atul Moghe Juniper Networks.
+
+import json
+import re
+import requests
+import socket
+import time
+import uuid
+from netaddr import IPNetwork, IPSet, IPAddress
+
+from neutron.api.v2 import attributes as attr
+from neutron.common import constants
+from neutron.common import exceptions
+from neutron.extensions import portbindings
+from vnc_api.common import exceptions as vnc_exc
+from vnc_api import vnc_api
+
+_DEFAULT_HEADERS = {
+    'Content-type': 'application/json; charset="UTF-8"', }
+
+CREATE = 1
+READ = 2
+UPDATE = 3
+DELETE = 4
+
+
+class DBInterface(object):
+    """
+    An instance of this class forwards requests to vnc cfg api (web)server
+    """
+    Q_URL_PREFIX = '/extensions/ct'
+
+    def __init__(self, admin_name, admin_password, admin_tenant_name,
+                 api_srvr_ip, api_srvr_port, user_info=None):
+        self._api_srvr_ip = api_srvr_ip
+        self._api_srvr_port = api_srvr_port
+
+        self._db_cache = {}
+        self._db_cache['q_networks'] = {}
+        self._db_cache['q_subnets'] = {}
+        self._db_cache['q_subnet_maps'] = {}
+        self._db_cache['q_policies'] = {}
+        self._db_cache['q_ipams'] = {}
+        self._db_cache['q_floatingips'] = {}
+        self._db_cache['q_ports'] = {}
+        self._db_cache['q_fixed_ip_to_subnet'] = {}
+        #obj-uuid to tenant-uuid mapping
+        self._db_cache['q_obj_to_tenant'] = {}
+        #port count per tenant-id
+        self._db_cache['q_tenant_port_count'] = {}
+        self._db_cache['vnc_networks'] = {}
+        self._db_cache['vnc_ports'] = {}
+        self._db_cache['vnc_projects'] = {}
+        self._db_cache['vnc_instance_ips'] = {}
+
+        # Retry till a api-server is up
+        connected = False
+        while not connected:
+            try:
+                self._vnc_lib = vnc_api.VncApi(
+                    admin_name, admin_password,
+                    admin_tenant_name, api_srvr_ip,
+                    api_srvr_port, '/', user_info=user_info)
+                connected = True
+            except requests.exceptions.RequestException:
+                time.sleep(3)
+
+        # changes 'net_fq_name_str pfx/len' key to 'net_id pfx/len' key
+        subnet_map = self._vnc_lib.kv_retrieve(key=None)
+        for kv_dict in subnet_map:
+            key = kv_dict['key']
+            if len(key.split()) == 1:
+                subnet_id = key
+                # uuid key, fixup value portion to 'net_id pfx/len' format
+                # if not already so
+                if len(kv_dict['value'].split(':')) == 1:
+                    # new format already, skip
+                    continue
+
+                net_fq_name = kv_dict['value'].split()[0].split(':')
+                try:
+                    net_obj = self._virtual_network_read(fq_name=net_fq_name)
+                except vnc_exc.NoIdError:
+                    self._vnc_lib.kv_delete(subnet_id)
+                    continue
+
+                new_subnet_key = '%s %s' % (net_obj.uuid,
+                                            kv_dict['value'].split()[1])
+                self._vnc_lib.kv_store(subnet_id, new_subnet_key)
+            else:  # subnet key
+                if len(key.split()[0].split(':')) == 1:
+                    # new format already, skip
+                    continue
+
+                # delete old key, convert to new key format and save
+                old_subnet_key = key
+                self._vnc_lib.kv_delete(old_subnet_key)
+
+                subnet_id = kv_dict['value']
+                net_fq_name = key.split()[0].split(':')
+                try:
+                    net_obj = self._virtual_network_read(fq_name=net_fq_name)
+                except vnc_exc.NoIdError:
+                    continue
+
+                new_subnet_key = '%s %s' % (net_obj.uuid, key.split()[1])
+                self._vnc_lib.kv_store(new_subnet_key, subnet_id)
+
+    # Helper routines
+    def _request_api_server(self, url, method, data=None, headers=None):
+        if method == 'GET':
+            return requests.get(url)
+        if method == 'POST':
+            return requests.post(url, data=data, headers=headers)
+        if method == 'DELETE':
+            return requests.delete(url)
+
+    def _relay_request(self, request):
+        """
+        Send received request to api server
+        """
+        # chop neutron parts of url and add api server address
+        url_path = re.sub(self.Q_URL_PREFIX, '', request.environ['PATH_INFO'])
+        url = "http://%s:%s%s" % (self._api_srvr_ip, self._api_srvr_port,
+                                  url_path)
+
+        return self._request_api_server(
+            url, request.environ['REQUEST_METHOD'],
+            request.body, {'Content-type': request.environ['CONTENT_TYPE']})
+
+    def _obj_to_json(self, obj):
+        return dict((k, v) for k, v in obj.__dict__.iteritems())
+
+    def _ensure_instance_exists(self, instance_id):
+        instance_name = instance_id
+        instance_obj = vnc_api.VirtualMachine(instance_name)
+        try:
+            id = self._vnc_lib.obj_to_id(instance_obj)
+            instance_obj = self._vnc_lib.virtual_machine_read(id=id)
+        except Exception as e:
+        #except vnc_exc.NoIdError:  # instance doesn't exist, create it
+            instance_obj.uuid = instance_id
+            self._vnc_lib.virtual_machine_create(instance_obj)
+
+        return instance_obj
+
+    def _ensure_default_security_group_exists(self, proj_id):
+        proj_obj = self._vnc_lib.project_read(id=proj_id)
+        sg_groups = proj_obj.get_security_groups()
+        for sg_group in sg_groups or []:
+            sg_obj = self._vnc_lib.security_group_read(id=sg_group['uuid'])
+            if sg_obj.name == 'default':
+                return
+
+        sg_obj = vnc_api.SecurityGroup(name='default', parent_obj=proj_obj)
+        self._vnc_lib.security_group_create(sg_obj)
+
+        #allow all egress traffic
+        def_rule = {}
+        def_rule['port_range_min'] = 0
+        def_rule['port_range_max'] = 65535
+        def_rule['direction'] = 'egress'
+        def_rule['remote_ip_prefix'] = None
+        def_rule['remote_group_id'] = None
+        def_rule['protocol'] = 'any'
+        rule = self._security_group_rule_neutron_to_vnc(def_rule, CREATE)
+        self._security_group_rule_create(sg_obj.uuid, rule)
+
+        #allow ingress traffic from within default security group
+        def_rule = {}
+        def_rule['port_range_min'] = 0
+        def_rule['port_range_max'] = 65535
+        def_rule['direction'] = 'ingress'
+        def_rule['remote_ip_prefix'] = None
+        def_rule['remote_group_id'] = None
+        def_rule['protocol'] = 'any'
+        rule = self._security_group_rule_neutron_to_vnc(def_rule, CREATE)
+        self._security_group_rule_create(sg_obj.uuid, rule)
+
+    def _get_obj_tenant_id(self, q_type, obj_uuid):
+        # Get the mapping from cache, else seed cache and return
+        try:
+            return self._db_cache['q_obj_to_tenant'][obj_uuid]
+        except KeyError:
+            # Seed the cache and return
+            if q_type == 'port':
+                port_obj = self._virtual_machine_interface_read(obj_uuid)
+                net_id = port_obj.get_virtual_network_refs()[0]['uuid']
+                # recurse up type-hierarchy
+                tenant_id = self._get_obj_tenant_id('network', net_id)
+                self._set_obj_tenant_id(obj_uuid, tenant_id)
+                return tenant_id
+
+            if q_type == 'network':
+                net_obj = self._virtual_network_read(net_id=obj_uuid)
+                tenant_id = net_obj.parent_uuid.replace('-', '')
+                self._set_obj_tenant_id(obj_uuid, tenant_id)
+                return tenant_id
+
+            return None
+
+    def _set_obj_tenant_id(self, obj_uuid, tenant_uuid):
+        self._db_cache['q_obj_to_tenant'][obj_uuid] = tenant_uuid
+
+    def _del_obj_tenant_id(self, obj_uuid):
+        try:
+            del self._db_cache['q_obj_to_tenant'][obj_uuid]
+        except Exception:
+            pass
+
+    def _project_read(self, proj_id=None, fq_name=None):
+        if proj_id:
+            try:
+                # disable cache for now as fip pool might be put without
+                # neutron knowing it
+                raise KeyError
+                #return self._db_cache['vnc_projects'][proj_id]
+            except KeyError:
+                proj_obj = self._vnc_lib.project_read(id=proj_id)
+                fq_name_str = json.dumps(proj_obj.get_fq_name())
+                self._db_cache['vnc_projects'][proj_id] = proj_obj
+                self._db_cache['vnc_projects'][fq_name_str] = proj_obj
+                return proj_obj
+
+        if fq_name:
+            fq_name_str = json.dumps(fq_name)
+            try:
+                # disable cache for now as fip pool might be put without
+                # neutron knowing it
+                raise KeyError
+                #return self._db_cache['vnc_projects'][fq_name_str]
+            except KeyError:
+                proj_obj = self._vnc_lib.project_read(fq_name=fq_name)
+                self._db_cache['vnc_projects'][fq_name_str] = proj_obj
+                self._db_cache['vnc_projects'][proj_obj.uuid] = proj_obj
+                return proj_obj
+
+    def _security_group_rule_create(self, sg_id, sg_rule):
+        sg_vnc = self._vnc_lib.security_group_read(id=sg_id)
+        rules = sg_vnc.get_security_group_entries()
+        if rules is None:
+            rules = vnc_api.PolicyEntriesType([sg_rule])
+        else:
+            rules.add_policy_rule(sg_rule)
+
+        sg_vnc.set_security_group_entries(rules)
+        self._vnc_lib.security_group_update(sg_vnc)
+        return
+
+    def _security_group_rule_find(self, sgr_id):
+        dom_projects = self._project_list_domain(None)
+        for project in dom_projects:
+            proj_id = project['uuid']
+            project_sgs = self._security_group_list_project(proj_id)
+
+            for sg in project_sgs:
+                sg_obj = self._vnc_lib.security_group_read(id=sg['uuid'])
+                sgr_entries = sg_obj.get_security_group_entries()
+                if sgr_entries is None:
+                    continue
+
+                for sg_rule in sgr_entries.get_policy_rule():
+                    if sg_rule.get_rule_uuid() == sgr_id:
+                        return sg_obj, sg_rule
+
+        return None, None
+
+    def _security_group_rule_delete(self, sg_obj, sg_rule):
+        rules = sg_obj.get_security_group_entries()
+        rules.get_policy_rule().remove(sg_rule)
+        sg_obj.set_security_group_entries(rules)
+        self._vnc_lib.security_group_update(sg_obj)
+        return
+
+    def _security_group_create(self, sg_obj):
+        sg_uuid = self._vnc_lib.security_group_create(sg_obj)
+        return sg_uuid
+
+    def _security_group_delete(self, sg_id):
+        self._vnc_lib.security_group_delete(id=sg_id)
+
+    def _svc_instance_create(self, si_obj):
+        si_uuid = self._vnc_lib.service_instance_create(si_obj)
+        st_fq_name = ['default-domain', 'nat-template']
+        st_obj = self._vnc_lib.service_template_read(fq_name=st_fq_name)
+        si_obj.set_service_template(st_obj)
+        self._vnc_lib.service_instance_update(si_obj)
+
+        return si_uuid
+
+    def _svc_instance_delete(self, si_id):
+        self._vnc_lib.service_instance_delete(id=si_id)
+
+    def _route_table_create(self, rt_obj):
+        rt_uuid = self._vnc_lib.route_table_create(rt_obj)
+        return rt_uuid
+
+    def _route_table_delete(self, rt_id):
+        self._vnc_lib.route_table_delete(id=rt_id)
+
+    def _virtual_network_create(self, net_obj):
+        net_uuid = self._vnc_lib.virtual_network_create(net_obj)
+
+        return net_uuid
+
+    def _virtual_network_read(self, net_id=None, fq_name=None):
+        if net_id:
+            try:
+                # return self._db_cache['vnc_networks'][net_id]
+                raise KeyError
+            except KeyError:
+                net_obj = self._vnc_lib.virtual_network_read(id=net_id)
+                fq_name_str = json.dumps(net_obj.get_fq_name())
+                self._db_cache['vnc_networks'][net_id] = net_obj
+                self._db_cache['vnc_networks'][fq_name_str] = net_obj
+                return net_obj
+
+        if fq_name:
+            fq_name_str = json.dumps(fq_name)
+            try:
+                # return self._db_cache['vnc_networks'][fq_name_str]
+                raise KeyError
+            except KeyError:
+                net_obj = self._vnc_lib.virtual_network_read(fq_name=fq_name)
+                self._db_cache['vnc_networks'][fq_name_str] = net_obj
+                self._db_cache['vnc_networks'][net_obj.uuid] = net_obj
+                return net_obj
+
+    def _virtual_network_update(self, net_obj):
+        self._vnc_lib.virtual_network_update(net_obj)
+        # read back to get subnet gw allocated by api-server
+        net_obj = self._vnc_lib.virtual_network_read(id=net_obj.uuid)
+        fq_name_str = json.dumps(net_obj.get_fq_name())
+
+        self._db_cache['vnc_networks'][net_obj.uuid] = net_obj
+        self._db_cache['vnc_networks'][fq_name_str] = net_obj
+
+    def _virtual_network_delete(self, net_id):
+        fq_name_str = None
+        try:
+            net_obj = self._db_cache['vnc_networks'][net_id]
+            fq_name_str = json.dumps(net_obj.get_fq_name())
+        except KeyError:
+            pass
+
+        self._vnc_lib.virtual_network_delete(id=net_id)
+
+        try:
+            del self._db_cache['vnc_networks'][net_id]
+            if fq_name_str:
+                del self._db_cache['vnc_networks'][fq_name_str]
+        except KeyError:
+            pass
+
+    def _virtual_machine_interface_create(self, port_obj):
+        port_uuid = self._vnc_lib.virtual_machine_interface_create(port_obj)
+
+        return port_uuid
+
+    def _virtual_machine_interface_read(self, port_id=None, fq_name=None):
+        if port_id:
+            try:
+                # return self._db_cache['vnc_ports'][port_id]
+                raise KeyError
+            except KeyError:
+                port_obj = self._vnc_lib.virtual_machine_interface_read(
+                    id=port_id)
+                fq_name_str = json.dumps(port_obj.get_fq_name())
+                self._db_cache['vnc_ports'][port_id] = port_obj
+                self._db_cache['vnc_ports'][fq_name_str] = port_obj
+                return port_obj
+
+        if fq_name:
+            fq_name_str = json.dumps(fq_name)
+            try:
+                # return self._db_cache['vnc_ports'][fq_name_str]
+                raise KeyError
+            except KeyError:
+                port_obj = self._vnc_lib.virtual_machine_interface_read(
+                    fq_name=fq_name)
+                self._db_cache['vnc_ports'][fq_name_str] = port_obj
+                self._db_cache['vnc_ports'][port_obj.uuid] = port_obj
+                return port_obj
+
+    def _virtual_machine_interface_update(self, port_obj):
+        self._vnc_lib.virtual_machine_interface_update(port_obj)
+        fq_name_str = json.dumps(port_obj.get_fq_name())
+
+        self._db_cache['vnc_ports'][port_obj.uuid] = port_obj
+        self._db_cache['vnc_ports'][fq_name_str] = port_obj
+
+    def _virtual_machine_interface_delete(self, port_id):
+        fq_name_str = None
+        try:
+            port_obj = self._db_cache['vnc_ports'][port_id]
+            fq_name_str = json.dumps(port_obj.get_fq_name())
+        except KeyError:
+            pass
+
+        self._vnc_lib.virtual_machine_interface_delete(id=port_id)
+
+        try:
+            del self._db_cache['vnc_ports'][port_id]
+            if fq_name_str:
+                del self._db_cache['vnc_ports'][fq_name_str]
+        except KeyError:
+            pass
+
+    def _instance_ip_create(self, iip_obj):
+        iip_uuid = self._vnc_lib.instance_ip_create(iip_obj)
+
+        return iip_uuid
+
+    def _instance_ip_read(self, instance_ip_id=None, fq_name=None):
+        if instance_ip_id:
+            try:
+                # return self._db_cache['vnc_instance_ips'][instance_ip_id]
+                raise KeyError
+            except KeyError:
+                iip_obj = self._vnc_lib.instance_ip_read(id=instance_ip_id)
+                fq_name_str = json.dumps(iip_obj.get_fq_name())
+                self._db_cache['vnc_instance_ips'][instance_ip_id] = iip_obj
+                self._db_cache['vnc_instance_ips'][fq_name_str] = iip_obj
+                return iip_obj
+
+        if fq_name:
+            fq_name_str = json.dumps(fq_name)
+            try:
+                # return self._db_cache['vnc_instance_ips'][fq_name_str]
+                raise KeyError
+            except KeyError:
+                iip_obj = self._vnc_lib.instance_ip_read(fq_name=fq_name)
+                self._db_cache['vnc_instance_ips'][fq_name_str] = iip_obj
+                self._db_cache['vnc_instance_ips'][iip_obj.uuid] = iip_obj
+                return iip_obj
+
+    def _instance_ip_update(self, iip_obj):
+        self._vnc_lib.instance_ip_update(iip_obj)
+        fq_name_str = json.dumps(iip_obj.get_fq_name())
+
+        self._db_cache['vnc_instance_ips'][iip_obj.uuid] = iip_obj
+        self._db_cache['vnc_instance_ips'][fq_name_str] = iip_obj
+
+    def _instance_ip_delete(self, instance_ip_id):
+        fq_name_str = None
+        try:
+            iip_obj = self._db_cache['vnc_instance_ips'][instance_ip_id]
+            fq_name_str = json.dumps(iip_obj.get_fq_name())
+        except KeyError:
+            pass
+
+        self._vnc_lib.instance_ip_delete(id=instance_ip_id)
+
+        try:
+            del self._db_cache['vnc_instance_ips'][instance_ip_id]
+            if fq_name_str:
+                del self._db_cache['vnc_instance_ips'][fq_name_str]
+        except KeyError:
+            pass
+
+    # find projects on a given domain
+    def _project_list_domain(self, domain_id):
+        fq_name = ['default-domain']
+        resp_dict = self._vnc_lib.projects_list(parent_fq_name=fq_name)
+
+        return resp_dict['projects']
+
+    # find network ids on a given project
+    def _network_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        resp_dict = self._vnc_lib.virtual_networks_list(parent_id=project_uuid)
+
+        return resp_dict['virtual-networks']
+
+    def _ipam_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        resp_dict = self._vnc_lib.network_ipams_list(parent_id=project_uuid)
+
+        return resp_dict['network-ipams']
+
+    def _security_group_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        self._ensure_default_security_group_exists(project_uuid)
+
+        resp_dict = self._vnc_lib.security_groups_list(parent_id=project_uuid)
+
+        return resp_dict['security-groups']
+
+    def _security_group_entries_list_sg(self, sg_id):
+        try:
+            sg_uuid = str(uuid.UUID(sg_id))
+        except Exception:
+            print "Error in converting SG uuid %s" % (sg_id)
+
+        resp_dict = self._vnc_lib.security_groups_list(parent_id=sg_uuid)
+
+        return resp_dict['security-groups']
+
+    def _route_table_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        resp_dict = self._vnc_lib.route_tables_list(parent_id=project_uuid)
+
+        return resp_dict['route-tables']
+
+    def _svc_instance_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        resp_dict = self._vnc_lib.service_instances_list(parent_id=project_uuid)
+
+        return resp_dict['service-instances']
+
+    def _policy_list_project(self, project_id):
+        try:
+            project_uuid = str(uuid.UUID(project_id))
+        except Exception:
+            print "Error in converting uuid %s" % (project_id)
+
+        resp_dict = self._vnc_lib.network_policys_list(parent_id=project_uuid)
+
+        return resp_dict['network-policys']
+
+    # find floating ip pools a project has access to
+    def _fip_pool_refs_project(self, project_id):
+        project_uuid = str(uuid.UUID(project_id))
+        project_obj = self._project_read(proj_id=project_uuid)
+
+        return project_obj.get_floating_ip_pool_refs()
+
+    # find networks of floating ip pools project has access to
+    def _fip_pool_ref_networks(self, project_id):
+        ret_nets = []
+
+        proj_fip_pool_refs = self._fip_pool_refs_project(project_id)
+        if not proj_fip_pool_refs:
+            return ret_nets
+
+        for fip_pool_ref in proj_fip_pool_refs:
+            fip_uuid = fip_pool_ref['uuid']
+            fip_pool_obj = self._vnc_lib.floating_ip_pool_read(id=fip_uuid)
+            net_uuid = fip_pool_obj.parent_uuid
+            net_obj = self._virtual_network_read(net_id=net_uuid)
+            ret_nets.append({'uuid': net_obj.uuid,
+                            'fq_name': net_obj.get_fq_name()})
+
+        return ret_nets
+
+    # find floating ip pools defined by network
+    def _fip_pool_list_network(self, net_id):
+        resp_dict = self._vnc_lib.floating_ip_pools_list(parent_id=net_id)
+
+        return resp_dict['floating-ip-pools']
+
+    # find port ids on a given network
+    def _port_list_network(self, network_id):
+        ret_list = []
+
+        try:
+            net_obj = self._virtual_network_read(net_id=network_id)
+        except vnc_exc.NoIdError:
+            return ret_list
+
+        port_back_refs = net_obj.get_virtual_machine_interface_back_refs()
+        if port_back_refs:
+            for port_back_ref in port_back_refs:
+                ret_list.append({'id': port_back_ref['uuid']})
+
+        return ret_list
+
+    # find port ids on a given project
+    def _port_list_project(self, project_id):
+        ret_list = []
+        project_nets = self._network_list_project(project_id)
+        for net in project_nets:
+            net_ports = self._port_list_network(net['uuid'])
+            ret_list.extend(net_ports)
+
+        return ret_list
+
+    # Returns True if
+    #     * no filter is specified
+    #     OR
+    #     * search-param is not present in filters
+    #     OR
+    #     * 1. search-param is present in filters AND
+    #       2. resource matches param-list AND
+    #       3. shared parameter in filters is False
+    def _filters_is_present(self, filters, key_name, match_value):
+        if filters:
+            if key_name in filters:
+                try:
+                    if ('shared' in filters and
+                            filters['shared'][0] is True):
+                        # yuck, q-api has shared as list always of 1 elem
+                        return False  # no shared-resource support
+                except ValueError:  # not in requested list
+                    return False
+            elif len(filters.keys()) == 1:
+                shared_val = filters.get('shared', None)
+                if shared_val and shared_val[0] is True:
+                    return False
+
+        return True
+
+    def _network_read(self, net_uuid):
+        net_obj = self._virtual_network_read(net_id=net_uuid)
+        return net_obj
+
+    def _subnet_vnc_create_mapping(self, subnet_id, subnet_key):
+        #import pdb; pdb.set_trace()
+        self._vnc_lib.kv_store(subnet_id, subnet_key)
+        self._vnc_lib.kv_store(subnet_key, subnet_id)
+        self._db_cache['q_subnet_maps'][subnet_id] = subnet_key
+        self._db_cache['q_subnet_maps'][subnet_key] = subnet_id
+
+    def _subnet_vnc_read_mapping(self, id=None, key=None):
+        if id:
+            try:
+                return self._db_cache['q_subnet_maps'][id]
+                #raise KeyError
+            except KeyError:
+                subnet_key = self._vnc_lib.kv_retrieve(id)
+                self._db_cache['q_subnet_maps'][id] = subnet_key
+                return subnet_key
+        if key:
+            try:
+                return self._db_cache['q_subnet_maps'][key]
+                #raise KeyError
+            except KeyError:
+                subnet_id = self._vnc_lib.kv_retrieve(key)
+                self._db_cache['q_subnet_maps'][key] = subnet_id
+                return subnet_id
+
+    def _subnet_vnc_read_or_create_mapping(self, id=None, key=None):
+        if id:
+            return self._subnet_vnc_read_mapping(id=id)
+
+        # if subnet was created outside of neutron handle it and create
+        # neutron representation now (lazily)
+        try:
+            return self._subnet_vnc_read_mapping(key=key)
+        except vnc_exc.NoIdError:
+            subnet_id = str(uuid.uuid4())
+            self._subnet_vnc_create_mapping(subnet_id, key)
+            return self._subnet_vnc_read_mapping(key=key)
+
+    def _subnet_vnc_delete_mapping(self, subnet_id, subnet_key):
+        self._vnc_lib.kv_delete(subnet_id)
+        self._vnc_lib.kv_delete(subnet_key)
+        try:
+            del self._db_cache['q_subnet_maps'][subnet_id]
+            del self._db_cache['q_subnet_maps'][subnet_key]
+        except KeyError:
+            pass
+
+    def _subnet_vnc_get_key(self, subnet_vnc, net_id):
+        pfx = subnet_vnc.subnet.get_ip_prefix()
+        pfx_len = subnet_vnc.subnet.get_ip_prefix_len()
+
+        return '%s %s/%s' % (net_id, pfx, pfx_len)
+
+    def _subnet_read(self, net_uuid, subnet_key):
+        try:
+            net_obj = self._virtual_network_read(net_id=net_uuid)
+        except vnc_exc.NoIdError:
+            return None
+
+        ipam_refs = net_obj.get_network_ipam_refs()
+        if not ipam_refs:
+            return None
+
+        for ipam_ref in ipam_refs:
+            subnet_vncs = ipam_ref['attr'].get_ipam_subnets()
+            for subnet_vnc in subnet_vncs:
+                if self._subnet_vnc_get_key(subnet_vnc,
+                                            net_uuid) == subnet_key:
+                    return subnet_vnc
+
+        return None
+
+    def _ip_address_to_subnet_id(self, ip_addr, net_obj):
+        # find subnet-id for ip-addr, called when instance-ip created
+        ipam_refs = net_obj.get_network_ipam_refs()
+        if ipam_refs:
+            for ipam_ref in ipam_refs:
+                subnet_vncs = ipam_ref['attr'].get_ipam_subnets()
+                for subnet_vnc in subnet_vncs:
+                    cidr = '%s/%s' % (subnet_vnc.subnet.get_ip_prefix(),
+                                      subnet_vnc.subnet.get_ip_prefix_len())
+                    if IPAddress(ip_addr) in IPSet([cidr]):
+                        subnet_key = self._subnet_vnc_get_key(subnet_vnc,
+                                                              net_obj.uuid)
+                        subnet_id = self._subnet_vnc_read_mapping(
+                            key=subnet_key)
+                        return subnet_id
+
+        return None
+
+    # Conversion routines between VNC and Quantum objects
+    def _svc_instance_neutron_to_vnc(self, si_q, oper):
+        if oper == CREATE:
+            project_id = str(uuid.UUID(si_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            net_id = si_q['internal_net']
+            int_vn = self._vnc_lib.virtual_network_read(id=net_id)
+            net_id = si_q['external_net']
+            ext_vn = self._vnc_lib.virtual_network_read(id=net_id)
+            scale_out = vnc_api.ServiceScaleOutType(max_instances=1,
+                                                    auto_scale=False)
+            si_prop = vnc_api.ServiceInstanceType(
+                auto_policy=True, left_virtual_network=int_vn.name,
+                right_virtual_network=ext_vn.name, scale_out=scale_out)
+            si_prop.set_scale_out(scale_out)
+            si_vnc = vnc_api.ServiceInstance(
+                name=si_q['name'],
+                parent_obj=project_obj,
+                service_instance_properties=si_prop)
+
+        return si_vnc
+
+    def _svc_instance_vnc_to_neutron(self, si_obj):
+        si_q_dict = json.loads(json.dumps(si_obj,
+                               default=self._obj_to_json))
+
+        # replace field names
+        si_q_dict['id'] = si_obj.uuid
+        si_q_dict['tenant_id'] = si_obj.parent_uuid.replace('-', '')
+        si_q_dict['name'] = si_obj.name
+        si_props = si_obj.get_service_instance_properties()
+        if si_props:
+            vn_fq_name = si_obj.get_parent_fq_name()
+            vn_name = si_props.get_left_virtual_network()
+            vn_fq_name.extend([vn_name])
+            vn_obj = self._vnc_lib.virtual_network_read(fq_name=vn_fq_name)
+            si_q_dict['internal_net'] = str(vn_obj.uuid) + ' ' + vn_name
+            vn_fq_name = si_obj.get_parent_fq_name()
+            vn_name = si_props.get_right_virtual_network()
+            vn_fq_name.extend([vn_name])
+            vn_obj = self._vnc_lib.virtual_network_read(fq_name=vn_fq_name)
+            si_q_dict['external_net'] = str(vn_obj.uuid) + ' ' + vn_name
+
+        return {'q_api_data': si_q_dict,
+                'q_extra_data': {}}
+
+    def _route_table_neutron_to_vnc(self, rt_q, oper):
+        if oper == CREATE:
+            project_id = str(uuid.UUID(rt_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            rt_vnc = vnc_api.RouteTable(name=rt_q['name'],
+                                        parent_obj=project_obj)
+            rt_vnc.set_routes(vnc_api.RouteTableType.factory(**rt_q['routes']))
+        else:
+            rt_vnc = self._vnc_lib.route_table_read(id=rt_q['id'])
+            rt_vnc.set_routes(vnc_api.RouteTableType.factory(**rt_q['routes']))
+
+        return rt_vnc
+
+    def _route_table_vnc_to_neutron(self, rt_obj):
+        rt_q_dict = json.loads(json.dumps(rt_obj,
+                               default=self._obj_to_json))
+
+        # replace field names
+        rt_q_dict['id'] = rt_obj.uuid
+        rt_q_dict['tenant_id'] = rt_obj.parent_uuid.replace('-', '')
+        rt_q_dict['name'] = rt_obj.name
+        rt_q_dict['fq_name'] = rt_obj.fq_name
+
+        # get route table routes
+        rt_q_dict['routes'] = rt_q_dict.pop('routes', None)
+        return {'q_api_data': rt_q_dict,
+                'q_extra_data': {}}
+
+    def _security_group_vnc_to_neutron(self, sg_obj):
+        sg_q_dict = json.loads(json.dumps(sg_obj,
+                               default=self._obj_to_json))
+
+        # replace field names
+        sg_q_dict['id'] = sg_obj.uuid
+        sg_q_dict['tenant_id'] = sg_obj.parent_uuid.replace('-', '')
+        sg_q_dict['name'] = sg_obj.name
+        sg_q_dict['description'] = sg_obj.get_id_perms().get_description()
+
+        # get security group rules
+        sg_q_dict['rules'] = []
+        rule_list = self.security_group_rules_read(sg_obj.uuid)
+        if rule_list:
+            for rule in rule_list:
+                sg_q_dict['rules'].append(rule['q_api_data'])
+
+        return {'q_api_data': sg_q_dict,
+                'q_extra_data': {}}
+
+    def _security_group_neutron_to_vnc(self, sg_q, oper):
+        if oper == CREATE:
+            project_id = str(uuid.UUID(sg_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            id_perms = vnc_api.IdPermsType(
+                enable=True, description=sg_q['description'])
+            sg_vnc = vnc_api.SecurityGroup(
+                name=sg_q['name'], parent_obj=project_obj,
+                id_perms=id_perms)
+
+        return sg_vnc
+
+    def _security_group_rule_vnc_to_neutron(self, sg_id, sg_rule):
+        sgr_q_dict = {}
+        if sg_id is None:
+            return {'q_api_data': sgr_q_dict,
+                    'q_extra_data': {}}
+
+        try:
+            sg_obj = self._vnc_lib.security_group_read(id=sg_id)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=sg_id)
+
+        direction = 'egress'
+        if sg_rule.get_direction() == '<':
+            direction = 'ingress'
+
+        remote_cidr = ''
+        remote_sg_uuid = ''
+        if direction == 'ingress':
+            addr = sg_rule.get_src_addresses()[0]
+        else:
+            addr = sg_rule.get_dst_addresses()[0]
+
+        if addr.get_subnet():
+            remote_cidr = '%s/%s' % (addr.get_subnet().get_ip_prefix(),
+                                     addr.get_subnet().get_ip_prefix_len())
+        elif addr.get_security_group():
+            if (addr.get_security_group() != 'any') and \
+                    (addr.get_security_group() != 'local'):
+                remote_sg = addr.get_security_group()
+                try:
+                    remote_sg_obj = self._vnc_lib.security_group_read(
+                        fq_name_str=remote_sg)
+                    remote_sg_uuid = remote_sg_obj.uuid
+                except vnc_exc.NoIdError:
+                    pass
+
+        sgr_q_dict['id'] = sg_rule.get_rule_uuid()
+        sgr_q_dict['tenant_id'] = sg_obj.parent_uuid.replace('-', '')
+        sgr_q_dict['security_group_id'] = sg_obj.uuid
+        sgr_q_dict['ethertype'] = 'IPv4'
+        sgr_q_dict['direction'] = direction
+        sgr_q_dict['protocol'] = sg_rule.get_protocol()
+        sgr_q_dict['port_range_min'] = sg_rule.get_dst_ports()[0].\
+            get_start_port()
+        sgr_q_dict['port_range_max'] = sg_rule.get_dst_ports()[0].\
+            get_end_port()
+        sgr_q_dict['remote_ip_prefix'] = remote_cidr
+        sgr_q_dict['remote_group_id'] = remote_sg_uuid
+
+        return {'q_api_data': sgr_q_dict,
+                'q_extra_data': {}}
+
+    def _security_group_rule_neutron_to_vnc(self, sgr_q, oper):
+        if oper == CREATE:
+            port_min = 0
+            port_max = 65535
+            if sgr_q['port_range_min']:
+                port_min = sgr_q['port_range_min']
+            if sgr_q['port_range_max']:
+                port_max = sgr_q['port_range_max']
+
+            endpt = [vnc_api.AddressType(security_group='any')]
+            if sgr_q['remote_ip_prefix']:
+                cidr = sgr_q['remote_ip_prefix'].split('/')
+                pfx = cidr[0]
+                pfx_len = int(cidr[1])
+                endpt = [vnc_api.AddressType(
+                    subnet=vnc_api.SubnetType(pfx, pfx_len))]
+            elif sgr_q['remote_group_id']:
+                sg_obj = self._vnc_lib.security_group_read(
+                    id=sgr_q['remote_group_id'])
+                endpt = [vnc_api.AddressType(
+                    security_group=sg_obj.get_fq_name_str())]
+
+            if sgr_q['direction'] == 'ingress':
+                dir = '<'
+                local = endpt
+                remote = [vnc_api.AddressType(security_group='local')]
+            else:
+                dir = '>'
+                remote = endpt
+                local = [vnc_api.AddressType(security_group='local')]
+
+            if not sgr_q['protocol']:
+                sgr_q['protocol'] = 'any'
+
+            sgr_uuid = str(uuid.uuid4())
+
+            rule = vnc_api.PolicyRuleType(
+                rule_uuid=sgr_uuid,
+                direction=dir,
+                protocol=sgr_q['protocol'],
+                src_addresses=local,
+                src_ports=[vnc_api.PortType(0, 65535)],
+                dst_addresses=remote,
+                dst_ports=[vnc_api.PortType(port_min, port_max)])
+            return rule
+
+    def _network_neutron_to_vnc(self, network_q, oper):
+        net_name = network_q.get('name', None)
+        if oper == CREATE:
+            project_id = str(uuid.UUID(network_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            id_perms = vnc_api.IdPermsType(enable=True)
+            net_obj = vnc_api.VirtualNetwork(
+                net_name, project_obj, id_perms=id_perms)
+        else:  # READ/UPDATE/DELETE
+            net_obj = self._virtual_network_read(net_id=network_q['id'])
+
+        id_perms = net_obj.get_id_perms()
+        if 'admin_state_up' in network_q:
+            id_perms.enable = network_q['admin_state_up']
+            net_obj.set_id_perms(id_perms)
+
+        if 'contrail:policys' in network_q:
+            policy_fq_names = network_q['contrail:policys']
+            # reset and add with newly specified list
+            net_obj.set_network_policy_list([], [])
+            seq = 0
+            for p_fq_name in policy_fq_names:
+                domain_name, project_name, policy_name = p_fq_name
+
+                domain_obj = vnc_api.Domain(domain_name)
+                project_obj = vnc_api.Project(project_name, domain_obj)
+                policy_obj = vnc_api.NetworkPolicy(policy_name, project_obj)
+
+                net_obj.add_network_policy(
+                    policy_obj,
+                    vnc_api.VirtualNetworkPolicyType(
+                        sequence=vnc_api.SequenceType(seq, 0)))
+                seq = seq + 1
+
+        if 'vpc:route_table' in network_q:
+            rt_fq_name = network_q['vpc:route_table']
+            if rt_fq_name:
+                try:
+                    rt_obj = self._vnc_lib.route_table_read(fq_name=rt_fq_name)
+                    net_obj.set_route_table(rt_obj)
+                except vnc_exc.NoIdError:
+                    raise exceptions.NetworkNotFound(net_id=net_obj.uuid)
+
+        return net_obj
+
+    def _network_vnc_to_neutron(self, net_obj, net_repr='SHOW'):
+        net_q_dict = {}
+        extra_dict = {}
+
+        net_q_dict['id'] = net_obj.uuid
+        net_q_dict['name'] = net_obj.name
+        extra_dict['contrail:fq_name'] = net_obj.get_fq_name()
+        net_q_dict['tenant_id'] = net_obj.parent_uuid.replace('-', '')
+        net_q_dict['admin_state_up'] = net_obj.get_id_perms().enable
+        net_q_dict['shared'] = False
+        net_q_dict['status'] = constants.NET_STATUS_ACTIVE
+
+        if net_repr == 'SHOW':
+            port_back_refs = net_obj.get_virtual_machine_interface_back_refs()
+            #if port_back_refs:
+            #    net_q_dict['ports'] = []
+            #    for port_back_ref in port_back_refs:
+            #        fq_name = port_back_ref['to']
+            #        try:
+            #            port_obj = self._virtual_machine_interface_read(
+            #                           port_id = fq_name[-1])
+            #        except NoIdError:
+            #            continue
+            #
+            #        port_info = self._port_vnc_to_neutron(port_obj, net_obj)
+            #        port_dict = port_info['q_api_data']
+            #        port_dict.update(port_info['q_extra_data'])
+            #
+            #        net_q_dict['ports'].append(port_dict)
+
+            extra_dict['contrail:instance_count'] = 0
+            if port_back_refs:
+                extra_dict['contrail:instance_count'] = len(port_back_refs)
+
+            net_policy_refs = net_obj.get_network_policy_refs()
+            if net_policy_refs:
+                extra_dict['contrail:policys'] = \
+                    [np_ref['to'] for np_ref in net_policy_refs]
+
+        elif net_repr == 'LIST':
+            extra_dict['contrail:instance_count'] = 0
+            port_back_refs = net_obj.get_virtual_machine_interface_back_refs()
+            if port_back_refs:
+                extra_dict['contrail:instance_count'] = len(port_back_refs)
+
+        ipam_refs = net_obj.get_network_ipam_refs()
+        net_q_dict['subnets'] = []
+        if ipam_refs:
+            extra_dict['contrail:subnet_ipam'] = []
+            for ipam_ref in ipam_refs:
+                subnets = ipam_ref['attr'].get_ipam_subnets()
+                for subnet in subnets:
+                    sn_info = self._subnet_vnc_to_neutron(subnet, net_obj,
+                                                          ipam_ref['to'])
+                    sn_dict = sn_info['q_api_data']
+                    sn_dict.update(sn_info['q_extra_data'])
+                    net_q_dict['subnets'].append(sn_dict)
+                    sn_ipam = {}
+                    sn_ipam['subnet_cidr'] = sn_dict['cidr']
+                    sn_ipam['ipam_fq_name'] = ipam_ref['to']
+                    extra_dict['contrail:subnet_ipam'].append(sn_ipam)
+
+        return {'q_api_data': net_q_dict,
+                'q_extra_data': extra_dict}
+
+    def _subnet_neutron_to_vnc(self, subnet_q):
+        cidr = subnet_q['cidr'].split('/')
+        pfx = cidr[0]
+        pfx_len = int(cidr[1])
+        if subnet_q['gateway_ip'] != attr.ATTR_NOT_SPECIFIED:
+            default_gw = subnet_q['gateway_ip']
+        else:
+            # Assigned by address manager
+            default_gw = None
+        sub_net = vnc_api.SubnetType(ip_prefix=pfx,
+                                     ip_prefix_len=pfx_len)
+        #subnet_vnc = vnc_api.IpamSubnetType(
+            #subnet=vnc_api.SubnetType(pfx, pfx_len),
+            #default_gateway=default_gw)
+        subnet_vnc = vnc_api.IpamSubnetType(subnet=sub_net,
+                                            default_gateway=default_gw)
+        return subnet_vnc
+
+    def _subnet_vnc_to_neutron(self, subnet_vnc, net_obj, ipam_fq_name):
+        sn_q_dict = {}
+        sn_q_dict['name'] = ''
+        sn_q_dict['tenant_id'] = net_obj.parent_uuid.replace('-', '')
+        sn_q_dict['network_id'] = net_obj.uuid
+        sn_q_dict['ip_version'] = 4
+
+        cidr = '%s/%s' % (subnet_vnc.subnet.get_ip_prefix(),
+                          subnet_vnc.subnet.get_ip_prefix_len())
+        sn_q_dict['cidr'] = cidr
+
+        subnet_key = self._subnet_vnc_get_key(subnet_vnc, net_obj.uuid)
+        sn_id = self._subnet_vnc_read_or_create_mapping(key=subnet_key)
+
+        sn_q_dict['id'] = sn_id
+
+        sn_q_dict['gateway_ip'] = subnet_vnc.default_gateway
+
+        first_ip = str(IPNetwork(cidr).network + 1)
+        last_ip = str(IPNetwork(cidr).broadcast - 2)
+        sn_q_dict['allocation_pools'] = \
+            [{'id': 'TODO-allocation_pools-id',
+             'subnet_id': sn_id,
+             'first_ip': first_ip,
+             'last_ip': last_ip,
+             'available_ranges': {}}]
+
+        sn_q_dict['enable_dhcp'] = False
+        sn_q_dict['dns_nameservers'] = [{'address': '169.254.169.254',
+                                        'subnet_id': sn_id}]
+
+        sn_q_dict['routes'] = [{'destination': 'TODO-destination',
+                               'nexthop': 'TODO-nexthop',
+                               'subnet_id': sn_id}]
+
+        sn_q_dict['shared'] = False
+
+        extra_dict = {}
+        extra_dict['contrail:instance_count'] = 0
+        extra_dict['contrail:ipam_fq_name'] = ipam_fq_name
+
+        return {'q_api_data': sn_q_dict,
+                'q_extra_data': extra_dict}
+
+    def _ipam_neutron_to_vnc(self, ipam_q, oper):
+        ipam_name = ipam_q.get('name', None)
+        if oper == CREATE:
+            project_id = str(uuid.UUID(ipam_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            ipam_obj = vnc_api.NetworkIpam(ipam_name, project_obj)
+        else:  # READ/UPDATE/DELETE
+            ipam_obj = self._vnc_lib.network_ipam_read(id=ipam_q['id'])
+
+        if ipam_q['mgmt']:
+            ipam_obj.set_network_ipam_mgmt(
+                vnc_api.IpamType.factory(**ipam_q['mgmt']))
+
+        return ipam_obj
+
+    def _ipam_vnc_to_neutron(self, ipam_obj):
+        ipam_q_dict = json.loads(json.dumps(ipam_obj,
+                                            default=self._obj_to_json))
+
+        # replace field names
+        ipam_q_dict['id'] = ipam_q_dict.pop('uuid')
+        ipam_q_dict['tenant_id'] = ipam_obj.parent_uuid.replace('-', '')
+        ipam_q_dict['mgmt'] = ipam_q_dict.pop('network_ipam_mgmt', None)
+        net_back_refs = ipam_q_dict.pop('virtual_network_back_refs', None)
+        if net_back_refs:
+            ipam_q_dict['nets_using'] = []
+            for net_back_ref in net_back_refs:
+                net_fq_name = net_back_ref['to']
+                ipam_q_dict['nets_using'].append(net_fq_name)
+
+        return {'q_api_data': ipam_q_dict,
+                'q_extra_data': {}}
+
+    def _policy_neutron_to_vnc(self, policy_q, oper):
+        policy_name = policy_q.get('name', None)
+        if oper == CREATE:
+            project_id = str(uuid.UUID(policy_q['tenant_id']))
+            project_obj = self._project_read(proj_id=project_id)
+            policy_obj = vnc_api.NetworkPolicy(policy_name, project_obj)
+        else:  # READ/UPDATE/DELETE
+            policy_obj = self._vnc_lib.network_policy_read(id=policy_q['id'])
+
+        policy_obj.set_network_policy_entries(
+            vnc_api.PolicyEntriesType.factory(**policy_q['entries']))
+
+        return policy_obj
+
+    def _policy_vnc_to_neutron(self, policy_obj):
+        policy_q_dict = json.loads(json.dumps(policy_obj,
+                                              default=self._obj_to_json))
+
+        # replace field names
+        policy_q_dict['id'] = policy_q_dict.pop('uuid')
+        policy_q_dict['tenant_id'] = policy_obj.uuid.replace('-', '')
+        policy_q_dict['entries'] = policy_q_dict.pop('network_policy_entries',
+                                                     None)
+        net_back_refs = policy_q_dict.pop('virtual_network_back_refs', None)
+        if net_back_refs:
+            policy_q_dict['nets_using'] = []
+            for net_back_ref in net_back_refs:
+                net_fq_name = net_back_ref['to']
+                policy_q_dict['nets_using'].append(net_fq_name)
+
+        return {'q_api_data': policy_q_dict,
+                'q_extra_data': {}}
+
+    def _floatingip_neutron_to_vnc(self, fip_q, oper):
+        if oper == CREATE:
+            # use first available pool on net
+            net_id = fip_q['floating_network_id']
+            fq_name = self._fip_pool_list_network(net_id)[0]['fq_name']
+            fip_pool_obj = self._vnc_lib.floating_ip_pool_read(fq_name=fq_name)
+            fip_name = str(uuid.uuid4())
+            fip_obj = vnc_api.FloatingIp(fip_name, fip_pool_obj)
+            fip_obj.uuid = fip_name
+
+            proj_id = str(uuid.UUID(fip_q['tenant_id']))
+            proj_obj = self._project_read(proj_id=proj_id)
+            fip_obj.set_project(proj_obj)
+        else:  # READ/UPDATE/DELETE
+            fip_obj = self._vnc_lib.floating_ip_read(id=fip_q['id'])
+
+        if fip_q['port_id']:
+            port_obj = self._virtual_machine_interface_read(
+                port_id=fip_q['port_id'])
+            fip_obj.set_virtual_machine_interface(port_obj)
+        else:
+            fip_obj.set_virtual_machine_interface_list([])
+
+        return fip_obj
+
+    def _floatingip_vnc_to_neutron(self, fip_obj):
+        fip_q_dict = {}
+        extra_dict = {}
+
+        fip_pool_obj = self._vnc_lib.floating_ip_pool_read(
+            id=fip_obj.parent_uuid)
+        net_obj = self._virtual_network_read(net_id=fip_pool_obj.parent_uuid)
+
+        tenant_id = fip_obj.get_project_refs()[0]['uuid'].replace('-', '')
+
+        port_id = None
+        port_refs = fip_obj.get_virtual_machine_interface_refs()
+        if port_refs:
+            port_id = fip_obj.get_virtual_machine_interface_refs()[0]['uuid']
+
+        fip_q_dict['id'] = fip_obj.uuid
+        fip_q_dict['tenant_id'] = tenant_id
+        fip_q_dict['floating_ip_address'] = fip_obj.get_floating_ip_address()
+        fip_q_dict['floating_network_id'] = net_obj.uuid
+        fip_q_dict['router_id'] = None
+        fip_q_dict['fixed_port_id'] = port_id
+        fip_q_dict['fixed_ip_address'] = None
+
+        return {'q_api_data': fip_q_dict,
+                'q_extra_data': extra_dict}
+
+    def _port_neutron_to_vnc(self, port_q, net_obj, oper):
+        if oper == CREATE:
+            port_name = str(uuid.uuid4())
+            instance_name = port_q['device_id']
+            instance_obj = vnc_api.VirtualMachine(instance_name)
+
+            id_perms = vnc_api.IdPermsType(enable=True)
+            port_obj = vnc_api.VirtualMachineInterface(port_name, instance_obj,
+                                                       id_perms=id_perms)
+            port_obj.uuid = port_name
+            port_obj.set_virtual_network(net_obj)
+
+        else:  # READ/UPDATE/DELETE
+            port_obj = self._virtual_machine_interface_read(
+                port_id=port_q['id'])
+
+        port_obj.set_security_group_list([])
+        if ('security_groups' in port_q and
+                port_q['security_groups'].__class__ is not object):
+            for sg_id in port_q['security_groups']:
+                sg_obj = self._vnc_lib.security_group_read(id=sg_id)
+                port_obj.add_security_group(sg_obj)
+
+        id_perms = port_obj.get_id_perms()
+        if 'admin_state_up' in port_q:
+            id_perms.enable = port_q['admin_state_up']
+            port_obj.set_id_perms(id_perms)
+
+        return port_obj
+
+    def _port_vnc_to_neutron(self, port_obj, net_obj=None):
+        port_q_dict = {}
+        port_q_dict['name'] = port_obj.uuid
+        port_q_dict['id'] = port_obj.uuid
+        port_q_dict[portbindings.VIF_TYPE] = portbindings.VIF_TYPE_CONTRAIL
+
+        if not net_obj:
+            net_refs = port_obj.get_virtual_network_refs()
+            if net_refs:
+                net_id = net_refs[0]['uuid']
+            else:
+                net_id = self._vnc_lib.obj_to_id(vnc_api.VirtualNetwork())
+
+            #proj_id = self._get_obj_tenant_id('port', port_obj.uuid)
+            proj_id = None
+            if not proj_id:
+                # not in cache, get by reading VN obj, and populate cache
+                net_obj = self._virtual_network_read(net_id=net_id)
+                proj_id = net_obj.parent_uuid.replace('-', '')
+                self._set_obj_tenant_id(port_obj.uuid, proj_id)
+        else:
+            net_id = net_obj.uuid
+            proj_id = net_obj.parent_uuid.replace('-', '')
+
+        port_q_dict['tenant_id'] = proj_id
+        port_q_dict['network_id'] = net_id
+
+        port_q_dict['mac_address'] = ''
+        mac_refs = port_obj.get_virtual_machine_interface_mac_addresses()
+        if mac_refs:
+            port_q_dict['mac_address'] = mac_refs.mac_address[0]
+
+        port_q_dict['fixed_ips'] = []
+        ip_back_refs = port_obj.get_instance_ip_back_refs()
+        if ip_back_refs:
+            for ip_back_ref in ip_back_refs:
+                try:
+                    ip_obj = self._instance_ip_read(
+                        instance_ip_id=ip_back_ref['uuid'])
+                except vnc_exc.NoIdError:
+                    continue
+
+                ip_addr = ip_obj.get_instance_ip_address()
+
+                ip_q_dict = {}
+                ip_q_dict['port_id'] = port_obj.uuid
+                ip_q_dict['ip_address'] = ip_addr
+                ip_q_dict['subnet_id'] = self._ip_address_to_subnet_id(ip_addr,
+                                                                       net_obj)
+                ip_q_dict['net_id'] = net_id
+
+                port_q_dict['fixed_ips'].append(ip_q_dict)
+
+        sg_dict = {'port_security_enabled': True}
+        sg_dict['security_groups'] = []
+        sg_refs = port_obj.get_security_group_refs()
+        for sg_ref in sg_refs or []:
+            sg_dict['security_groups'].append(sg_ref['uuid'])
+
+        port_q_dict['admin_state_up'] = port_obj.get_id_perms().enable
+        port_q_dict['status'] = constants.PORT_STATUS_ACTIVE
+        port_q_dict['device_id'] = port_obj.parent_name
+        port_q_dict['device_owner'] = 'TODO-device-owner'
+
+        return {'q_api_data': port_q_dict,
+                'q_extra_data': sg_dict}
+
+    # public methods
+    # network api handlers
+    def network_create(self, network_q):
+        #self._ensure_project_exists(network_q['tenant_id'])
+
+        net_obj = self._network_neutron_to_vnc(network_q, CREATE)
+        net_uuid = self._virtual_network_create(net_obj)
+
+        ret_network_q = self._network_vnc_to_neutron(net_obj, net_repr='SHOW')
+        self._db_cache['q_networks'][net_uuid] = ret_network_q
+
+        return ret_network_q
+
+    def network_read(self, net_uuid, fields=None):
+        # see if we can return fast...
+        if fields and (len(fields) == 1) and fields[0] == 'tenant_id':
+            tenant_id = self._get_obj_tenant_id('network', net_uuid)
+            return {'q_api_data': {'id': net_uuid, 'tenant_id': tenant_id}}
+
+        try:
+            # return self._db_cache['q_networks']['net_uuid']
+            raise KeyError
+        except KeyError:
+            pass
+
+        try:
+            net_obj = self._network_read(net_uuid)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=net_uuid)
+
+        return self._network_vnc_to_neutron(net_obj, net_repr='SHOW')
+
+    def network_update(self, net_id, network_q):
+        network_q['id'] = net_id
+        net_obj = self._network_neutron_to_vnc(network_q, UPDATE)
+        self._virtual_network_update(net_obj)
+
+        ret_network_q = self._network_vnc_to_neutron(net_obj, net_repr='SHOW')
+        self._db_cache['q_networks'][net_id] = ret_network_q
+
+        return ret_network_q
+
+    def network_delete(self, net_id):
+        self._virtual_network_delete(net_id=net_id)
+        try:
+            del self._db_cache['q_networks'][net_id]
+        except KeyError:
+            pass
+
+    def network_list(self, filters=None):
+        ret_list = []
+
+        if filters and 'shared' in filters:
+            if filters['shared'][0] is True:
+                # no support for shared networks
+                return ret_list
+
+        # collect phase
+        all_nets = []  # all n/ws in all projects
+        if filters and 'tenant_id' in filters:
+            # project-id is present
+            if 'id' in filters:
+                # required networks are also specified,
+                # just read and populate ret_list
+                # prune is skipped because all_nets is empty
+                for net_id in filters['id']:
+                    net_obj = self._network_read(net_id)
+                    net_info = self._network_vnc_to_neutron(net_obj,
+                                                            net_repr='LIST')
+                    ret_list.append(net_info)
+            else:
+                # read all networks in project, and prune below
+                project_ids = filters['tenant_id']
+                for p_id in project_ids:
+                    if 'router:external' in filters:
+                        all_nets.append(self._fip_pool_ref_networks(p_id))
+                    else:
+                        project_nets = self._network_list_project(p_id)
+                        all_nets.append(project_nets)
+        elif filters and 'id' in filters:
+            # required networks are specified, just read and populate ret_list
+            # prune is skipped because all_nets is empty
+            for net_id in filters['id']:
+                net_obj = self._network_read(net_id)
+                net_info = self._network_vnc_to_neutron(net_obj,
+                                                        net_repr='LIST')
+                ret_list.append(net_info)
+        else:
+            # read all networks in all projects
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                if filters and 'router:external' in filters:
+                    all_nets.append(self._fip_pool_ref_networks(proj_id))
+                else:
+                    project_nets = self._network_list_project(proj_id)
+                    all_nets.append(project_nets)
+
+        # prune phase
+        for project_nets in all_nets:
+            for proj_net in project_nets:
+                proj_net_id = proj_net['uuid']
+                if not self._filters_is_present(filters, 'id', proj_net_id):
+                    continue
+
+                proj_net_fq_name = unicode(proj_net['fq_name'])
+                if not self._filters_is_present(filters, 'contrail:fq_name',
+                                                proj_net_fq_name):
+                    continue
+
+                try:
+                    net_obj = self._network_read(proj_net['uuid'])
+                    net_info = self._network_vnc_to_neutron(net_obj,
+                                                            net_repr='LIST')
+                except vnc_exc.NoIdError:
+                    continue
+                ret_list.append(net_info)
+
+        return ret_list
+
+    def network_count(self, filters=None):
+        nets_info = self.network_list(filters)
+        return len(nets_info)
+
+    # subnet api handlers
+    def subnet_create(self, subnet_q):
+        net_id = subnet_q['network_id']
+        net_obj = self._virtual_network_read(net_id=net_id)
+
+        ipam_fq_name = subnet_q['contrail:ipam_fq_name']
+        if ipam_fq_name != '':
+            domain_name, project_name, ipam_name = ipam_fq_name
+
+            project_obj = vnc_api.Project(project_name)
+            netipam_obj = vnc_api.NetworkIpam(ipam_name, project_obj)
+        else:  # link subnet with default ipam
+            project_obj = vnc_api.Project(net_obj.parent_name)
+            netipam_obj = vnc_api.NetworkIpam(project_obj=project_obj)
+            ipam_fq_name = netipam_obj.get_fq_name()
+
+        subnet_vnc = self._subnet_neutron_to_vnc(subnet_q)
+        subnet_key = self._subnet_vnc_get_key(subnet_vnc, net_id)
+
+        # Locate list of subnets to which this subnet has to be appended
+        net_ipam_ref = None
+        ipam_refs = net_obj.get_network_ipam_refs()
+        if ipam_refs:
+            for ipam_ref in ipam_refs:
+                if ipam_ref['to'] == ipam_fq_name:
+                    net_ipam_ref = ipam_ref
+                    break
+
+        if not net_ipam_ref:
+            # First link from net to this ipam
+            vnsn_data = vnc_api.VnSubnetsType(ipam_subnets=[subnet_vnc])
+            net_obj.add_network_ipam(netipam_obj, vnsn_data)
+        else:  # virtual-network already linked to this ipam
+            for subnet in net_ipam_ref['attr'].get_ipam_subnets():
+                if subnet_key == self._subnet_vnc_get_key(subnet, net_id):
+                    # duplicate !!
+                    subnet_info = self._subnet_vnc_to_neutron(subnet,
+                                                              net_obj,
+                                                              ipam_fq_name)
+                    return subnet_info
+            vnsn_data = net_ipam_ref['attr']
+            vnsn_data.ipam_subnets.append(subnet_vnc)
+
+        self._virtual_network_update(net_obj)
+
+        # allocate an id to the subnet and store mapping with
+        # api-server
+        subnet_id = str(uuid.uuid4())
+        self._subnet_vnc_create_mapping(subnet_id, subnet_key)
+
+        # Read in subnet from server to get updated values for gw etc.
+        subnet_vnc = self._subnet_read(net_obj.uuid, subnet_key)
+        subnet_info = self._subnet_vnc_to_neutron(subnet_vnc, net_obj,
+                                                  ipam_fq_name)
+
+        #self._db_cache['q_subnets'][subnet_id] = subnet_info
+
+        return subnet_info
+
+    def subnet_read(self, subnet_id):
+        try:
+            # return self._db_cache['q_subnets'][subnet_id]
+            raise KeyError
+        except KeyError:
+            pass
+
+        subnet_key = self._subnet_vnc_read_mapping(id=subnet_id)
+        net_id = subnet_key.split()[0]
+
+        net_obj = self._network_read(net_id)
+        ipam_refs = net_obj.get_network_ipam_refs()
+        if ipam_refs:
+            for ipam_ref in ipam_refs:
+                subnet_vncs = ipam_ref['attr'].get_ipam_subnets()
+                for subnet_vnc in subnet_vncs:
+                    if self._subnet_vnc_get_key(subnet_vnc,
+                                                net_id) == subnet_key:
+                        ret_subnet_q = self._subnet_vnc_to_neutron(
+                            subnet_vnc, net_obj, ipam_ref['to'])
+                        self._db_cache['q_subnets'][subnet_id] = ret_subnet_q
+                        return ret_subnet_q
+
+        return {}
+
+    def subnet_delete(self, subnet_id):
+        subnet_key = self._subnet_vnc_read_mapping(id=subnet_id)
+        net_id = subnet_key.split()[0]
+
+        net_obj = self._network_read(net_id)
+        ipam_refs = net_obj.get_network_ipam_refs()
+        if ipam_refs:
+            for ipam_ref in ipam_refs:
+                orig_subnets = ipam_ref['attr'].get_ipam_subnets()
+                new_subnets = [subnet_vnc for subnet_vnc in orig_subnets
+                               if self._subnet_vnc_get_key(subnet_vnc, net_id)
+                               != subnet_key]
+                if len(orig_subnets) != len(new_subnets):
+                    # matched subnet to be deleted
+                    ipam_ref['attr'].set_ipam_subnets(new_subnets)
+                    self._virtual_network_update(net_obj)
+                    self._subnet_vnc_delete_mapping(subnet_id, subnet_key)
+                    try:
+                        del self._db_cache['q_subnets'][subnet_id]
+                    except KeyError:
+                        pass
+
+                    return
+
+    def subnets_list(self, filters=None):
+        ret_subnets = []
+
+        if filters and 'id' in filters:
+            # required subnets are specified,
+            # just read in corresponding net_ids
+            net_ids = set([])
+            for subnet_id in filters['id']:
+                subnet_key = self._subnet_vnc_read_mapping(id=subnet_id)
+                net_id = subnet_key.split()[0]
+                net_ids.add(net_id)
+        else:
+            nets_info = self.network_list()
+            net_ids = [n_info['q_api_data']['id'] for n_info in nets_info]
+
+        for net_id in net_ids:
+            net_obj = self._network_read(net_id)
+            ipam_refs = net_obj.get_network_ipam_refs()
+            if ipam_refs:
+                for ipam_ref in ipam_refs:
+                    subnet_vncs = ipam_ref['attr'].get_ipam_subnets()
+                    for subnet_vnc in subnet_vncs:
+                        sn_info = self._subnet_vnc_to_neutron(subnet_vnc,
+                                                              net_obj,
+                                                              ipam_ref['to'])
+                        sn_id = sn_info['q_api_data']['id']
+                        sn_proj_id = sn_info['q_api_data']['tenant_id']
+                        sn_net_id = sn_info['q_api_data']['network_id']
+
+                        if filters:
+                            if not self._filters_is_present(filters, 'id',
+                                                            sn_id):
+                                continue
+                            if not self._filters_is_present(filters,
+                                                            'tenant_id',
+                                                            sn_proj_id):
+                                continue
+                            if not self._filters_is_present(filters,
+                                                            'network_id',
+                                                            sn_net_id):
+                                continue
+
+                        ret_subnets.append(sn_info)
+
+        return ret_subnets
+
+    def subnets_count(self, filters=None):
+        subnets_info = self.subnets_list(filters)
+        return len(subnets_info)
+
+    # ipam api handlers
+    def ipam_create(self, ipam_q):
+        ipam_obj = self._ipam_neutron_to_vnc(ipam_q, CREATE)
+        self._vnc_lib.network_ipam_create(ipam_obj)
+
+        return self._ipam_vnc_to_neutron(ipam_obj)
+
+    def ipam_read(self, ipam_id):
+        try:
+            ipam_obj = self._vnc_lib.network_ipam_read(id=ipam_id)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=ipam_id)
+
+        return self._ipam_vnc_to_neutron(ipam_obj)
+
+    def ipam_update(self, ipam_id, ipam):
+        ipam_q = ipam['ipam']
+        ipam_q['id'] = ipam_id
+        ipam_obj = self._ipam_neutron_to_vnc(ipam_q, UPDATE)
+        self._vnc_lib.network_ipam_update(ipam_obj)
+
+        return self._ipam_vnc_to_neutron(ipam_obj)
+
+    def ipam_delete(self, ipam_id):
+        self._vnc_lib.network_ipam_delete(id=ipam_id)
+
+    def ipam_list(self, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_ipams = []  # all ipams in all projects
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_ipams = self._ipam_list_project(p_id)
+                all_ipams.append(project_ipams)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_ipams = self._ipam_list_project(proj_id)
+                all_ipams.append(project_ipams)
+
+        # prune phase
+        for project_ipams in all_ipams:
+            for proj_ipam in project_ipams:
+                proj_ipam_id = proj_ipam['uuid']
+                if not self._filters_is_present(filters, 'id', proj_ipam_id):
+                    continue
+                ipam_info = self.ipam_read(proj_ipam['uuid'])
+                ret_list.append(ipam_info)
+
+        return ret_list
+
+    def ipam_count(self, filters=None):
+        ipam_info = self.ipam_list(filters)
+        return len(ipam_info)
+
+    # policy api handlers
+    def policy_create(self, policy_q):
+
+        policy_obj = self._policy_neutron_to_vnc(policy_q, CREATE)
+        self._vnc_lib.network_policy_create(policy_obj)
+
+        return self._policy_vnc_to_neutron(policy_obj)
+
+    def policy_read(self, policy_id):
+        policy_obj = self._vnc_lib.network_policy_read(id=policy_id)
+
+        return self._policy_vnc_to_neutron(policy_obj)
+
+    def policy_update(self, policy_id, policy):
+        policy_q = policy['policy']
+        policy_q['id'] = policy_id
+        policy_obj = self._policy_neutron_to_vnc(policy_q, UPDATE)
+        self._vnc_lib.network_policy_update(policy_obj)
+
+        return self._policy_vnc_to_neutron(policy_obj)
+
+    def policy_delete(self, policy_id):
+        self._vnc_lib.network_policy_delete(id=policy_id)
+
+    def policy_list(self, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_policys = []  # all policys in all projects
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_policys = self._policy_list_project(p_id)
+                all_policys.append(project_policys)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_policys = self._policy_list_project(proj_id)
+                all_policys.append(project_policys)
+
+        # prune phase
+        for project_policys in all_policys:
+            for proj_policy in project_policys:
+                proj_policy_id = proj_policy['uuid']
+                if not self._filters_is_present(filters, 'id', proj_policy_id):
+                    continue
+                policy_info = self.policy_read(proj_policy['uuid'])
+                ret_list.append(policy_info)
+
+        return ret_list
+
+    def policy_count(self, filters=None):
+        policy_info = self.policy_list(filters)
+        return len(policy_info)
+
+    # floatingip api handlers
+    def floatingip_create(self, fip_q):
+        fip_obj = self._floatingip_neutron_to_vnc(fip_q, CREATE)
+        fip_uuid = self._vnc_lib.floating_ip_create(fip_obj)
+        fip_obj = self._vnc_lib.floating_ip_read(id=fip_uuid)
+
+        return self._floatingip_vnc_to_neutron(fip_obj)
+
+    def floatingip_read(self, fip_uuid):
+        fip_obj = self._vnc_lib.floating_ip_read(id=fip_uuid)
+
+        return self._floatingip_vnc_to_neutron(fip_obj)
+
+    def floatingip_update(self, fip_id, fip_q):
+        fip_q['id'] = fip_id
+        fip_obj = self._floatingip_neutron_to_vnc(fip_q, UPDATE)
+        self._vnc_lib.floating_ip_update(fip_obj)
+
+        return self._floatingip_vnc_to_neutron(fip_obj)
+
+    def floatingip_delete(self, fip_id):
+        self._vnc_lib.floating_ip_delete(id=fip_id)
+
+    def floatingip_list(self, filters=None):
+        # Find networks, get floatingip backrefs and return
+        ret_list = []
+
+        if filters:
+            if 'tenant_id' in filters:
+                proj_ids = [str(uuid.UUID(id)) for id in filters['tenant_id']]
+            elif 'port_id' in filters:
+                # required ports are specified, just read and populate ret_list
+                # prune is skipped because proj_objs is empty
+                proj_ids = []
+                for port_id in filters['port_id']:
+                    port_obj = self._virtual_machine_interface_read(
+                        port_id=port_id)
+                    fip_back_refs = port_obj.get_floating_ip_back_refs()
+                    if not fip_back_refs:
+                        continue
+                    for fip_back_ref in fip_back_refs:
+                        fip_obj = self._vnc_lib.floating_ip_read(
+                            id=fip_back_ref['uuid'])
+                        ret_list.append(self._floatingip_vnc_to_neutron(
+                            fip_obj))
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            proj_ids = [proj['uuid'] for proj in dom_projects]
+
+        proj_objs = [self._project_read(proj_id=id) for id in proj_ids]
+
+        for proj_obj in proj_objs:
+            fip_back_refs = proj_obj.get_floating_ip_back_refs()
+            if not fip_back_refs:
+                continue
+            for fip_back_ref in fip_back_refs:
+                fip_obj = self._vnc_lib.floating_ip_read(
+                    id=fip_back_ref['uuid'])
+                ret_list.append(self._floatingip_vnc_to_neutron(fip_obj))
+
+        return ret_list
+
+    def floatingip_count(self, filters=None):
+        floatingip_info = self.floatingip_list(filters)
+        return len(floatingip_info)
+
+    # port api handlers
+    def port_create(self, port_q):
+        net_id = port_q['network_id']
+        net_obj = self._network_read(net_id)
+        proj_id = net_obj.parent_uuid
+
+        self._ensure_instance_exists(port_q['device_id'])
+
+        # initialize port object
+        port_obj = self._port_neutron_to_vnc(port_q, net_obj, CREATE)
+
+        # if ip address passed then use it
+        ip_addr = None
+        ip_obj = None
+        if port_q['fixed_ips'].__class__ is not object:
+            ip_addr = port_q['fixed_ips'][0]['ip_address']
+            ip_name = '%s %s' % (net_id, ip_addr)
+            try:
+                ip_obj = self._instance_ip_read(fq_name=[ip_name])
+                #ip_id = ip_obj.uuid
+            except Exception as e:
+                ip_obj = None
+
+        # create the object
+        port_id = self._virtual_machine_interface_create(port_obj)
+
+        # initialize ip object
+        if ip_obj is None:
+            ip_name = str(uuid.uuid4())
+            ip_obj = vnc_api.InstanceIp(name=ip_name)
+            ip_obj.uuid = ip_name
+            ip_obj.set_virtual_machine_interface(port_obj)
+            ip_obj.set_virtual_network(net_obj)
+            if ip_addr:
+                ip_obj.set_instance_ip_address(ip_addr)
+            try:
+                self._instance_ip_create(ip_obj)
+            except Exception as e:
+                # ResourceExhaustionError, resources are not available
+                self._virtual_machine_interface_delete(port_id=port_id)
+                raise e
+        # shared ip address
+        else:
+            if ip_addr == ip_obj.get_instance_ip_address():
+                ip_obj.add_virtual_machine_interface(port_obj)
+                self._instance_ip_update(ip_obj)
+
+        port_obj = self._virtual_machine_interface_read(port_id=port_id)
+
+        ret_port_q = self._port_vnc_to_neutron(port_obj, net_obj)
+        #self._db_cache['q_ports'][port_id] = ret_port_q
+        self._set_obj_tenant_id(port_id, proj_id)
+
+        # update cache on successful creation
+        tenant_id = proj_id.replace('-', '')
+        if tenant_id not in self._db_cache['q_tenant_port_count']:
+            ncurports = self.port_count({'tenant_id': tenant_id})
+        else:
+            ncurports = self._db_cache['q_tenant_port_count'][tenant_id]
+
+        self._db_cache['q_tenant_port_count'][tenant_id] = ncurports + 1
+
+        return ret_port_q
+
+    def port_read(self, port_id):
+        try:
+            # return self._db_cache['q_ports'][port_id]
+            raise KeyError
+        except KeyError:
+            pass
+
+        port_obj = self._virtual_machine_interface_read(port_id=port_id)
+
+        ret_port_q = self._port_vnc_to_neutron(port_obj)
+        self._db_cache['q_ports'][port_id] = ret_port_q
+
+        return ret_port_q
+
+    def port_update(self, port_id, port_q):
+        port_q['id'] = port_id
+        port_obj = self._port_neutron_to_vnc(port_q, None, UPDATE)
+        self._virtual_machine_interface_update(port_obj)
+
+        ret_port_q = self._port_vnc_to_neutron(port_obj)
+        self._db_cache['q_ports'][port_id] = ret_port_q
+
+        return ret_port_q
+
+    def port_delete(self, port_id):
+        port_obj = self._port_neutron_to_vnc({'id': port_id}, None, READ)
+        instance_id = port_obj.parent_uuid
+
+        # release instance IP address
+        iip_back_refs = port_obj.get_instance_ip_back_refs()
+        if iip_back_refs:
+            for iip_back_ref in iip_back_refs:
+                # if name contains IP address then this is shared ip
+                iip_obj = self._vnc_lib.instance_ip_read(
+                    id=iip_back_ref['uuid'])
+                name = iip_obj.name
+                if len(name.split(' ')) > 1:
+                    name = name.split(' ')[1]
+
+                # in case of shared ip only delete the link to the VMI
+                try:
+                    socket.inet_aton(name)
+                    iip_obj.del_virtual_machine_interface(port_obj)
+                    self._instance_ip_update(iip_obj)
+                except socket.error:
+                    self._instance_ip_delete(
+                        instance_ip_id=iip_back_ref['uuid'])
+
+        # disassociate any floating IP used by instance
+        fip_back_refs = port_obj.get_floating_ip_back_refs()
+        if fip_back_refs:
+            for fip_back_ref in fip_back_refs:
+                fip_obj = self._vnc_lib.floating_ip_read(
+                    id=fip_back_ref['uuid'])
+                self.floatingip_update(fip_obj.uuid, {'port_id': None})
+
+        self._virtual_machine_interface_delete(port_id=port_id)
+
+        # delete instance if this was the last port
+        inst_obj = self._vnc_lib.virtual_machine_read(id=instance_id)
+        inst_intfs = inst_obj.get_virtual_machine_interfaces()
+        if not inst_intfs:
+            self._vnc_lib.virtual_machine_delete(id=inst_obj.uuid)
+
+        try:
+            del self._db_cache['q_ports'][port_id]
+        except KeyError:
+            pass
+
+        # update cache on successful deletion
+        try:
+            tenant_id = self._get_obj_tenant_id('port', port_id)
+            self._db_cache['q_tenant_port_count'][tenant_id] = \
+                self._db_cache['q_tenant_port_count'][tenant_id] - 1
+        except KeyError:
+            pass
+
+        self._del_obj_tenant_id(port_id)
+
+    def port_list(self, filters=None):
+        ret_q_ports = []
+        all_project_ids = []
+
+        if 'device_owner' in filters:
+            return ret_q_ports
+
+        if 'device_id' not in filters:
+            # Listing from back references
+            if not filters:
+                # no filters => return all ports!
+                all_projects = self._project_list_domain(None)
+                all_project_ids = [project['uuid'] for project in all_projects]
+            elif 'tenant_id' in filters:
+                all_project_ids = filters.get('tenant_id')
+
+            for proj_id in all_project_ids:
+                proj_ports = self._port_list_project(proj_id)
+                for port in proj_ports:
+                    try:
+                        port_info = self.port_read(port['id'])
+                    except vnc_exc.NoIdError:
+                        continue
+                    ret_q_ports.append(port_info)
+
+            for net_id in filters.get('network_id', []):
+                net_ports = self._port_list_network(net_id)
+                for port in net_ports:
+                    port_info = self.port_read(port['id'])
+                    ret_q_ports.append(port_info)
+
+            return ret_q_ports
+
+        # Listing from parent to children
+        virtual_machine_ids = filters['device_id']
+        for vm_id in virtual_machine_ids:
+            resp_dict = self._vnc_lib.virtual_machine_interfaces_list(
+                parent_id=vm_id)
+            vm_intf_ids = resp_dict['virtual-machine-interfaces']
+            for vm_intf in vm_intf_ids:
+                try:
+                    port_info = self.port_read(vm_intf['uuid'])
+                except vnc_exc.NoIdError:
+                    continue
+                ret_q_ports.append(port_info)
+
+        return ret_q_ports
+
+    def port_count(self, filters=None):
+        if 'device_owner' in filters:
+            return 0
+
+        if 'tenant_id' in filters:
+            project_id = filters['tenant_id'][0]
+            try:
+                return self._db_cache['q_tenant_port_count'][project_id]
+            except KeyError:
+                # do it the hard way but remember for next time
+                nports = len(self._port_list_project(project_id))
+                self._db_cache['q_tenant_port_count'][project_id] = nports
+        else:
+            # across all projects
+            # get only a count from api-server!
+            nports = len(self.port_list(filters))
+
+        return nports
+
+    # security group api handlers
+    def security_group_create(self, sg_q):
+        sg_obj = self._security_group_neutron_to_vnc(sg_q, CREATE)
+        sg_uuid = self._security_group_create(sg_obj)
+
+        #allow all egress traffic
+        def_rule = {}
+        def_rule['port_range_min'] = 0
+        def_rule['port_range_max'] = 65535
+        def_rule['direction'] = 'egress'
+        def_rule['remote_ip_prefix'] = None
+        def_rule['remote_group_id'] = None
+        def_rule['protocol'] = 'any'
+        rule = self._security_group_rule_neutron_to_vnc(def_rule, CREATE)
+        self._security_group_rule_create(sg_uuid, rule)
+
+        ret_sg_q = self._security_group_vnc_to_neutron(sg_obj)
+        return ret_sg_q
+
+    def security_group_read(self, sg_id):
+        try:
+            sg_obj = self._vnc_lib.security_group_read(id=sg_id)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=sg_id)
+
+        return self._security_group_vnc_to_neutron(sg_obj)
+
+    def security_group_delete(self, sg_id):
+        self._security_group_delete(sg_id)
+
+    def security_group_list(self, context, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_sgs = []  # all sgs in all projects
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_sgs = self._security_group_list_project(p_id)
+                all_sgs.append(project_sgs)
+        elif filters and 'name' in filters:
+            p_id = str(uuid.UUID(context.tenant))
+            project_sgs = self._security_group_list_project(p_id)
+            all_sgs.append(project_sgs)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_sgs = self._security_group_list_project(proj_id)
+                all_sgs.append(project_sgs)
+
+        # prune phase
+        for project_sgs in all_sgs:
+            for proj_sg in project_sgs:
+                proj_sg_id = proj_sg['uuid']
+                if not self._filters_is_present(filters, 'id', proj_sg_id):
+                    continue
+                sg_info = self.security_group_read(proj_sg_id)
+                if not self._filters_is_present(filters, 'name',
+                                                sg_info['q_api_data']['name']):
+                    continue
+                ret_list.append(sg_info)
+
+        return ret_list
+
+    def security_group_rule_create(self, sgr_q):
+        sg_id = sgr_q['security_group_id']
+        sg_rule = self._security_group_rule_neutron_to_vnc(sgr_q, CREATE)
+        self._security_group_rule_create(sg_id, sg_rule)
+        ret_sg_rule_q = self._security_group_rule_vnc_to_neutron(sg_id,
+                                                                 sg_rule)
+
+        return ret_sg_rule_q
+
+    def security_group_rule_read(self, sgr_id):
+        sg_obj, sg_rule = self._security_group_rule_find(sgr_id)
+        if sg_obj and sg_rule:
+            return self._security_group_rule_vnc_to_neutron(sg_obj.uuid,
+                                                            sg_rule)
+
+        return {}
+
+    def security_group_rule_delete(self, sgr_id):
+        sg_obj, sg_rule = self._security_group_rule_find(sgr_id)
+        if sg_obj and sg_rule:
+            return self._security_group_rule_delete(sg_obj, sg_rule)
+
+    def security_group_rules_read(self, sg_id):
+        try:
+            sg_obj = self._vnc_lib.security_group_read(id=sg_id)
+            sgr_entries = sg_obj.get_security_group_entries()
+            sg_rules = []
+            if sgr_entries is None:
+                return
+
+            for sg_rule in sgr_entries.get_policy_rule():
+                sg_info = self._security_group_rule_vnc_to_neutron(sg_obj.uuid,
+                                                                   sg_rule)
+                sg_rules.append(sg_info)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=sg_id)
+
+        return sg_rules
+
+    def security_group_rule_list(self, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_sgs = []
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_sgs = self._security_group_list_project(p_id)
+                all_sgs.append(project_sgs)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_sgs = self._security_group_list_project(proj_id)
+                all_sgs.append(project_sgs)
+
+        # prune phase
+        for project_sgs in all_sgs:
+            for proj_sg in project_sgs:
+                proj_sg_id = proj_sg['uuid']
+                if not self._filters_is_present(filters, 'id', proj_sg_id):
+                    continue
+                sgr_info = self.security_group_rules_read(proj_sg_id)
+                if sgr_info:
+                    ret_list.append(sgr_info)
+
+        return ret_list
+
+    #route table api handlers
+    def route_table_create(self, rt_q):
+        rt_obj = self._route_table_neutron_to_vnc(rt_q, CREATE)
+        self._route_table_create(rt_obj)
+        ret_rt_q = self._route_table_vnc_to_neutron(rt_obj)
+        return ret_rt_q
+
+    def route_table_read(self, rt_id):
+        try:
+            rt_obj = self._vnc_lib.route_table_read(id=rt_id)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=rt_id)
+
+        return self._route_table_vnc_to_neutron(rt_obj)
+
+    def route_table_update(self, rt_id, rt_q):
+        rt_q['id'] = rt_id
+        rt_obj = self._route_table_neutron_to_vnc(rt_q, UPDATE)
+        self._vnc_lib.route_table_update(rt_obj)
+        return self._route_table_vnc_to_neutron(rt_obj)
+
+    def route_table_delete(self, rt_id):
+        self._route_table_delete(rt_id)
+
+    def route_table_list(self, context, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_rts = []  # all rts in all projects
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_rts = self._route_table_list_project(p_id)
+                all_rts.append(project_rts)
+        elif filters and 'name' in filters:
+            p_id = str(uuid.UUID(context.tenant))
+            project_rts = self._route_table_list_project(p_id)
+            all_rts.append(project_rts)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_rts = self._route_table_list_project(proj_id)
+                all_rts.append(project_rts)
+
+        # prune phase
+        for project_rts in all_rts:
+            for proj_rt in project_rts:
+                proj_rt_id = proj_rt['uuid']
+                if not self._filters_is_present(filters, 'id', proj_rt_id):
+                    continue
+                rt_info = self.route_table_read(proj_rt_id)
+                if not self._filters_is_present(filters, 'name',
+                                                rt_info['q_api_data']['name']):
+                    continue
+                ret_list.append(rt_info)
+
+        return ret_list
+
+    #service instance api handlers
+    def svc_instance_create(self, si_q):
+        si_obj = self._svc_instance_neutron_to_vnc(si_q, CREATE)
+        self._svc_instance_create(si_obj)
+        ret_si_q = self._svc_instance_vnc_to_neutron(si_obj)
+        return ret_si_q
+
+    def svc_instance_read(self, si_id):
+        try:
+            si_obj = self._vnc_lib.service_instance_read(id=si_id)
+        except vnc_exc.NoIdError:
+            raise exceptions.NetworkNotFound(net_id=si_id)
+
+        return self._svc_instance_vnc_to_neutron(si_obj)
+
+    def svc_instance_delete(self, si_id):
+        self._svc_instance_delete(si_id)
+
+    def svc_instance_list(self, context, filters=None):
+        ret_list = []
+
+        # collect phase
+        all_sis = []  # all sis in all projects
+        if filters and 'tenant_id' in filters:
+            project_ids = filters['tenant_id']
+            for p_id in project_ids:
+                project_sis = self._svc_instance_list_project(p_id)
+                all_sis.append(project_sis)
+        elif filters and 'name' in filters:
+            p_id = str(uuid.UUID(context.tenant))
+            project_sis = self._svc_instance_list_project(p_id)
+            all_sis.append(project_sis)
+        else:  # no filters
+            dom_projects = self._project_list_domain(None)
+            for project in dom_projects:
+                proj_id = project['uuid']
+                project_sis = self._svc_instance_list_project(proj_id)
+                all_sis.append(project_sis)
+
+        # prune phase
+        for project_sis in all_sis:
+            for proj_si in project_sis:
+                proj_si_id = proj_si['uuid']
+                if not self._filters_is_present(filters, 'id', proj_si_id):
+                    continue
+                si_info = self.svc_instance_read(proj_si_id)
+                if not self._filters_is_present(filters, 'name',
+                                                si_info['q_api_data']['name']):
+                    continue
+                ret_list.append(si_info)
+
+        return ret_list
diff --git neutron/tests/unit/juniper/__init__.py neutron/tests/unit/juniper/__init__.py
new file mode 100644
index 0000000..72bebec
--- /dev/null
+++ neutron/tests/unit/juniper/__init__.py
@@ -0,0 +1,14 @@
+# Copyright (c) 2012 OpenStack Foundation.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+# implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git neutron/tests/unit/juniper/test_contrail_plugin.py neutron/tests/unit/juniper/test_contrail_plugin.py
new file mode 100644
index 0000000..decf79e
--- /dev/null
+++ neutron/tests/unit/juniper/test_contrail_plugin.py
@@ -0,0 +1,998 @@
+# Copyright (c) 2012 OpenStack Foundation.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+# implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import datetime
+import mock
+import neutron.db.api
+from neutron.manager import NeutronManager
+from neutron.tests.unit import test_db_plugin as test_plugin
+import sys
+import uuid
+
+subnet_obj = {u'subnet':
+              {'name': '', 'enable_dhcp': True,
+               u'network_id': u'b11ffca3-3dfc-435e-ae0e-8f44da7188b7',
+               'tenant_id': u'8162e75da480419a8b2ae7088dbc14f5',
+               'dns_nameservers': '',
+               u'contrail:ipam_fq_name':
+               [u'default-domain', u'admin', u'default-network-ipam'],
+               'allocation_pools': '', 'host_routes': '', u'ip_version': 4,
+               'gateway_ip': '', u'cidr': u'20.20.1.0/29'}}
+
+vn_list = []
+GlobalProjects = []
+
+
+class MockVncApi(mock.MagicMock):
+    def __init__(self, *args, **kwargs):
+        pass
+
+    def kv_retrieve(self, *args, **kwargs):
+        return []
+
+    def kv_store(self, *args, **kwargs):
+        return
+
+    def kv_delete(self, *args, **kwargs):
+        return
+
+    def project_read(self, *args, **kwargs):
+        #return MockProject('dummy-proj')
+        return GlobalProjects[0]
+
+    def virtual_network_create(self, net_obj):
+        net_id = unicode(str(uuid.uuid4()))
+        net_obj.set_uuid(net_id)
+        vn_list.append(net_obj)
+        return net_id
+
+    def virtual_network_read(self, id, *args, **kwargs):
+        if len(vn_list):
+            for index in range(len(vn_list)):
+                if ((vn_list[index].get_uuid()) == id):
+                    return vn_list[index]
+
+        #return a mock object if it is not created so far
+        return MockVirtualNetwork('dummy-net', MockProject())
+
+    def virtual_network_delete(self, *args, **kwargs):
+        return
+
+    def virtual_network_update(self, *args, **kwargs):
+        return
+
+    def virtual_networks_list(self, *args, **kwargs):
+        return vn_list
+
+
+class MockVncObject(mock.MagicMock):
+    def __init__(self, name=None, parent_obj=None, *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        if not parent_obj:
+            self._fq_name = [name]
+        else:
+            self._fq_name = parent_obj.get_fq_name() + [name]
+
+        self._ipam_refs = [{'to': [u'default-domain', u'admin',
+                           u'default-network-ipam']}]
+        self.uuid = None
+        self.name = name
+        self.network_ipam_refs = []
+
+    def set_uuid(self, uuid):
+        self.uuid = uuid
+
+    def get_uuid(self):
+        return self.uuid
+
+    def get_fq_name(self):
+        return self._fq_name
+
+    def get_network_ipam_refs(self):
+        return getattr(self, 'network_ipam_refs', None)
+
+    def add_network_ipam(self, ref_obj, ref_data):
+        refs = getattr(self, 'network_ipam_refs', [])
+        if not refs:
+            self.network_ipam_refs = []
+
+        # if ref already exists, update any attr with it
+        for ref in refs:
+            if ref['to'] == ref_obj.get_fq_name():
+                ref = {'to': ref_obj.get_fq_name(), 'attr': ref_data}
+                if ref_obj.uuid:
+                    ref['uuid'] = ref_obj.uuid
+                return
+
+        # ref didn't exist before
+        ref_info = {'to': ref_obj.get_fq_name(), 'attr': ref_data}
+        if ref_obj.uuid:
+            ref_info['uuid'] = ref_obj.uuid
+
+        self.network_ipam_refs.append(ref_info)
+
+
+class MockVirtualNetwork(MockVncObject):
+    pass
+
+
+class MockSubnetType(mock.MagicMock):
+    def __init__(self, name=None, ip_prefix=None, ip_prefix_len=None,
+                 *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        self.ip_prefix = ip_prefix
+        self.ip_prefix_len = ip_prefix_len
+
+    def get_ip_prefix(self):
+        return self.ip_prefix
+
+    def set_ip_prefix(self, ip_prefix):
+        self.ip_prefix = ip_prefix
+
+    def get_ip_prefix_len(self):
+        return self.ip_prefix_len
+
+    def set_ip_prefix_len(self, ip_prefix_len):
+        self.ip_prefix_len = ip_prefix_len
+
+
+class MockIpamSubnetType(mock.MagicMock):
+    def __init__(self, name=None, subnet=None, default_gateway=None,
+                 *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        self.subnet = subnet
+        self.default_gateway = default_gateway
+
+    def get_subnet(self):
+        return self.subnet
+
+    def set_subnet(self, subnet):
+        self.subnet = subnet
+
+    def get_default_gateway(self):
+        return self.default_gateway
+
+    def set_default_gateway(self, default_gateway):
+        self.default_gateway = default_gateway
+
+    def validate_IpAddressType(self, value):
+        pass
+
+
+class MockVnSubnetsType(mock.MagicMock):
+    def __init__(self, name=None, parent_obj=None, ipam_subnets=None,
+                 *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        self.ipam_subnets = []
+        if ipam_subnets:
+            #self.ipam_subnets = copy.deepcopy(ipam_subnets)
+            self.ipam_subnets = ipam_subnets
+
+    def get_ipam_subnets(self):
+        return self.ipam_subnets
+
+    def set_ipam_subnets(self, ipam_subnets):
+        self.ipam_subnets = ipam_subnets
+
+    def add_ipam_subnets(self, value):
+        self.ipam_subnets.append(value)
+
+    def insert_ipam_subnets(self, index, value):
+        self.ipam_subnets[index] = value
+
+    def delete_ipam_subnets(self, value):
+        self.ipam_subnets.remove(value)
+
+
+class MockNetworkIpam(mock.MagicMock):
+    def __init__(self, name=None, parent_obj=None,
+                 network_ipam_mgmt=None, id_perms=None,
+                 *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        self._type = 'default-network-ipam'
+        self.name = name
+        self.uuid = None
+        if parent_obj:
+            self.parent_type = parent_obj._type
+            # copy parent's fq_name
+            self.fq_name = list(parent_obj.fq_name)
+            self.fq_name.append(name)
+            if not parent_obj.get_network_ipams():
+                parent_obj.network_ipams = []
+            parent_obj.network_ipams.append(self)
+        else:  # No parent obj specified
+            self.parent_type = 'project'
+            self.fq_name = [u'default-domain', u'default-project']
+            self.fq_name.append(name)
+
+        # property fields
+        if network_ipam_mgmt:
+            self.network_ipam_mgmt = network_ipam_mgmt
+        if id_perms:
+            self.id_perms = id_perms
+
+    def get_fq_name(self):
+        return self.fq_name
+
+
+class MockProject(mock.MagicMock):
+    def __init__(self, name=None, parent_obj=None, id_perms=None,
+                 *args, **kwargs):
+        super(mock.MagicMock, self).__init__()
+        self._type = 'project'
+        self.uuid = None
+        self.parent_type = 'domain'
+        self.fq_name = [u'default-domain']
+        self.fq_name.append(name)
+
+    def get_fq_name(self):
+        return self.fq_name
+
+
+def GlobalProjectApi(project_name):
+    if not GlobalProjects:
+        GlobalProjects.append(MockProject(name=project_name))
+
+    return GlobalProjects[0]
+
+
+# Mock definations for different pkgs, modules and VncApi
+mock_vnc_api_cls = mock.MagicMock(name='MockVncApi', side_effect=MockVncApi)
+mock_vnc_api_mod = mock.MagicMock(name='vnc_api_mock_mod')
+mock_vnc_api_mod.VncApi = mock_vnc_api_cls
+mock_vnc_api_mod.VirtualNetwork = MockVirtualNetwork
+mock_vnc_api_mod.SubnetType = MockSubnetType
+mock_vnc_api_mod.IpamSubnetType = MockIpamSubnetType
+mock_vnc_api_mod.VnSubnetsType = MockVnSubnetsType
+mock_vnc_api_mod.NetworkIpam = MockNetworkIpam
+mock_vnc_api_mod.Project = GlobalProjectApi
+
+mock_vnc_api_pkg = mock.MagicMock(name='vnc_api_mock_pkg')
+mock_vnc_api_pkg.vnc_api = mock_vnc_api_mod
+mock_vnc_common_mod = mock.MagicMock(name='vnc_common_mock_mod')
+mock_vnc_exception_mod = mock.MagicMock(name='vnc_exception_mock_mod')
+sys.modules['neutron.plugins.juniper.contrail.ctdb.vnc_api'] = \
+    mock_vnc_api_pkg
+sys.modules['neutron.plugins.juniper.contrail.ctdb.vnc_api.vnc_api'] = \
+    mock_vnc_api_mod
+sys.modules['neutron.plugins.juniper.contrail.ctdb.vnc_api.common'] = \
+    mock_vnc_common_mod
+sys.modules[('neutron.plugins.juniper.contrail.ctdb.vnc_api.common.'
+             'exceptions')] = \
+    mock_vnc_exception_mod
+
+CONTRAIL_PKG_PATH = "neutron.plugins.juniper.contrail.contrailplugin"
+
+
+class RouterInstance(object):
+    def __init__(self):
+        self._name = 'rounter_instance'
+
+
+class Context(object):
+    def __init__(self, tenant_id=''):
+        self.read_only = False
+        self.show_deleted = False
+        self.roles = [u'admin', u'KeystoneServiceAdmin', u'KeystoneAdmin']
+        self._read_deleted = 'no'
+        self.timestamp = datetime.datetime.now()
+        self.auth_token = None
+        self._session = None
+        self._is_admin = True
+        self.admin = uuid.uuid4().hex.decode()
+        self.request_id = 'req-' + str(uuid.uuid4())
+        self.tenant = tenant_id
+
+
+class JVContrailPluginTestCase(test_plugin.NeutronDbPluginV2TestCase):
+    _plugin_name = ('%s.ContrailPlugin' % CONTRAIL_PKG_PATH)
+
+    def setUp(self):
+
+        mock_vnc_common_mod.exceptions = mock_vnc_exception_mod
+
+        mock_vnc_api_mod.common = mock_vnc_common_mod
+        mock_vnc_api_mod.VncApi = mock_vnc_api_cls
+
+        mock_vnc_api_pkg.vnc_api = mock_vnc_api_mod
+
+        super(JVContrailPluginTestCase, self).setUp(self._plugin_name)
+        neutron.db.api._ENGINE = mock.MagicMock()
+
+    def teardown(self):
+        super(JVContrailPluginTestCase, self).setUp(self._plugin_name)
+
+
+class TestContrailNetworks(test_plugin.TestNetworksV2,
+                           JVContrailPluginTestCase):
+
+    def test_create_network(self):
+        plugin_obj = NeutronManager.get_plugin()
+        networks_req = {}
+        network = {}
+        router_inst = RouterInstance()
+        network['router:external'] = router_inst
+        network[u'name'] = u'network1'
+        network['admin_state_up'] = 'True'
+        network['tenant_id'] = uuid.uuid4().hex.decode()
+        network['vpc:route_table'] = ''
+        network['shared'] = False
+        network['port_security_enabled'] = True
+        network[u'contrail:policys'] = []
+
+        networks_req[u'network'] = network
+        context_obj = Context(network['tenant_id'])
+
+        #create project
+        if not GlobalProjects:
+            project_name = 'admin'
+            GlobalProjects.append(MockProject(name=project_name))
+
+        net = plugin_obj.create_network(context_obj, networks_req)
+        if 'contrail:fq_name' not in net.keys():
+            assert False
+        else:
+            assert True
+
+    def test_delete_network(self):
+        # First create the network and request to delete the same
+        plugin_obj = NeutronManager.get_plugin()
+        networks_req = {}
+        network = {}
+        router_inst = RouterInstance()
+        network['router:external'] = router_inst
+        network[u'name'] = u'network1'
+        network['admin_state_up'] = 'True'
+        network['tenant_id'] = uuid.uuid4().hex.decode()
+        network['vpc:route_table'] = ''
+        network['shared'] = False
+        network['port_security_enabled'] = True
+        network[u'contrail:policys'] = []
+
+        context_obj = Context(network['tenant_id'])
+        #create project
+        if not GlobalProjects:
+            project_name = 'admin'
+            GlobalProjects.append(MockProject(name=project_name))
+
+        networks_req[u'network'] = network
+        net_dict = plugin_obj.create_network(context_obj, networks_req)
+        net_id = net_dict.get('id')
+
+        plugin_obj.delete_network(context_obj, net_id)
+        mock_vnc_api_cls.virtual_network_delete.assert_called_once()
+
+    def test_update_network(self):
+        plugin_obj = NeutronManager.get_plugin()
+        networks_req = {}
+        network = {}
+        router_inst = RouterInstance()
+        network['router:external'] = router_inst
+        network[u'name'] = u'network1'
+        network['admin_state_up'] = 'True'
+        network['tenant_id'] = uuid.uuid4().hex.decode()
+        network['vpc:route_table'] = ''
+        network['shared'] = False
+        network['port_security_enabled'] = True
+        network[u'contrail:policys'] = []
+
+        context_obj = Context(network['tenant_id'])
+        #create project
+        if not GlobalProjects:
+            project_name = 'admin'
+            GlobalProjects.append(MockProject(name=project_name))
+
+        networks_req[u'network'] = network
+        net_dict = plugin_obj.create_network(context_obj, networks_req)
+        net_id = net_dict.get('id')
+        # change one of the attribute and update the network
+        network['admin_state_up'] = 'False'
+        new_dict = plugin_obj.update_network(context_obj, net_id,
+                                             networks_req)
+        if (net_dict.get('admin_state_up') == new_dict.get('admin_state_up')):
+            assert False
+        else:
+            assert True
+
+    # Not supported test cases in the this TestClass
+    def test_create_networks_bulk_emulated(self):
+        pass
+
+    def test_create_networks_bulk_emulated_plugin_failure(self):
+        pass
+
+    def test_create_public_network(self):
+        pass
+
+    def test_create_networks_bulk_wrong_input(self):
+        pass
+
+    def test_update_shared_network_noadmin_returns_403(self):
+        pass
+
+    def test_update_network_set_shared(self):
+        pass
+
+    def test_update_network_set_not_shared_multi_tenants_returns_409(self):
+        pass
+
+    def test_update_network_set_not_shared_multi_tenants2_returns_409(self):
+        pass
+
+    def test_update_network_set_not_shared_single_tenant(self):
+        pass
+
+    def test_update_network_set_not_shared_other_tenant_returns_409(self):
+        pass
+
+    def test_update_network_with_subnet_set_shared(self):
+        pass
+
+    def test_show_network(self):
+        pass
+
+    def test_show_network_with_subnet(self):
+        pass
+
+    def test_list_networks(self):
+        pass
+
+    def test_list_shared_networks_with_non_admin_user(self):
+        pass
+
+    def test_list_networks_with_parameters(self):
+        pass
+
+    def test_list_networks_with_fields(self):
+        pass
+
+    def test_list_networks_with_parameters_invalid_values(self):
+        pass
+
+    def test_list_networks_with_pagination_emulated(self):
+        pass
+
+    def test_list_networks_without_pk_in_fields_pagination_emulated(self):
+        pass
+
+    def test_list_networks_with_sort_emulated(self):
+        pass
+
+    def test_list_networks_with_pagination_reverse_emulated(self):
+        pass
+
+    def test_invalid_admin_status(self):
+        pass
+
+
+class TestContrailSubnetsV2(test_plugin.TestSubnetsV2,
+                            JVContrailPluginTestCase):
+
+    def test_create_subnet(self):
+        #First create virtual network without subnet and then
+        #create subnet to update given network.
+        plugin_obj = NeutronManager.get_plugin()
+        networks_req = {}
+        network = {}
+        router_inst = RouterInstance()
+        network['router:external'] = router_inst
+        network[u'name'] = u'network1'
+        network['admin_state_up'] = 'True'
+        network['tenant_id'] = uuid.uuid4().hex.decode()
+        network['vpc:route_table'] = ''
+        network['shared'] = False
+        network['port_security_enabled'] = True
+        network[u'contrail:policys'] = []
+
+        networks_req[u'network'] = network
+        context_obj = Context(network['tenant_id'])
+        #create project
+        if not GlobalProjects:
+            project_name = 'admin'
+            GlobalProjects.append(MockProject(name=project_name))
+
+        net = plugin_obj.create_network(context_obj, networks_req)
+
+        subnet_obj[u'subnet']['network_id'] = net['id']
+        subnet_dict = plugin_obj.create_subnet(context_obj, subnet_obj)
+        if subnet_dict['cidr'] != subnet_obj['subnet']['cidr']:
+            assert False
+        else:
+            assert True
+
+    def test_delete_subnet(self):
+        #First create virtual network without subnet and then
+        #create subnet to update given network.
+        plugin_obj = NeutronManager.get_plugin()
+        networks_req = {}
+        network = {}
+        router_inst = RouterInstance()
+        network['router:external'] = router_inst
+        network[u'name'] = u'network1'
+        network['admin_state_up'] = 'True'
+        network['tenant_id'] = uuid.uuid4().hex.decode()
+        network['vpc:route_table'] = ''
+        network['shared'] = False
+        network['port_security_enabled'] = True
+        network[u'contrail:policys'] = []
+
+        networks_req[u'network'] = network
+        context_obj = Context(network['tenant_id'])
+        #create project
+        if not GlobalProjects:
+            project_name = 'admin'
+            GlobalProjects.append(MockProject(name=project_name))
+
+        net = plugin_obj.create_network(context_obj, networks_req)
+
+        subnet_obj[u'subnet']['network_id'] = net['id']
+        subnet_dict = plugin_obj.create_subnet(context_obj, subnet_obj)
+        subnet_id = subnet_dict['id']
+        plugin_obj.delete_subnet(context_obj, subnet_id)
+
+    def test_update_subnet_gateway_in_allocation_pool_returns_409(self):
+        pass
+
+    def test_delete_network(self):
+        pass
+
+    def test_update_subnet_gw_outside_cidr_force_on_returns_400(self):
+        pass
+
+    def test_update_subnet_adding_additional_host_routes_and_dns(self):
+        pass
+
+    def test_update_subnet_no_gateway(self):
+        pass
+
+    def test_create_subnet_bad_cidr(self):
+        pass
+
+    def test_create_subnet_gw_of_network_force_on_returns_400(self):
+        pass
+
+    def test_create_subnet_gw_outside_cidr_force_on_returns_400(self):
+        pass
+
+    def test_create_two_subnets(self):
+        pass
+
+    def test_create_two_subnets_same_cidr_returns_400(self):
+        pass
+
+    def test_create_subnet_bad_V4_cidr(self):
+        pass
+
+    def test_create_subnet_bad_V6_cidr(self):
+        pass
+
+    def test_create_2_subnets_overlapping_cidr_allowed_returns_200(self):
+        pass
+
+    def test_create_2_subnets_overlapping_cidr_not_allowed_returns_400(self):
+        pass
+
+    def test_create_subnets_bulk_native(self):
+        pass
+
+    def test_create_subnets_bulk_emulated(self):
+        pass
+
+    def test_create_subnets_bulk_emulated_plugin_failure(self):
+        pass
+
+    def test_create_subnets_bulk_native_plugin_failure(self):
+        pass
+
+    def test_delete_subnet_port_exists_owned_by_network(self):
+        pass
+
+    def test_delete_subnet_port_exists_owned_by_other(self):
+        pass
+
+    def test_create_subnet_bad_tenant(self):
+        pass
+
+    def test_create_subnet_bad_ip_version(self):
+        pass
+
+    def test_create_subnet_bad_ip_version_null(self):
+        pass
+
+    def test_create_subnet_bad_uuid(self):
+        pass
+
+    def test_create_subnet_bad_boolean(self):
+        pass
+
+    def test_create_subnet_bad_pools(self):
+        pass
+
+    def test_create_subnet_bad_nameserver(self):
+        pass
+
+    def test_create_subnet_bad_hostroutes(self):
+        pass
+
+    def test_create_subnet_defaults(self):
+        pass
+
+    def test_create_subnet_gw_values(self):
+        pass
+
+    def test_create_force_subnet_gw_values(self):
+        pass
+
+    def test_create_subnet_with_allocation_pool(self):
+        pass
+
+    def test_create_subnet_with_none_gateway(self):
+        pass
+
+    def test_create_subnet_with_none_gateway_fully_allocated(self):
+        pass
+
+    def test_subnet_with_allocation_range(self):
+        pass
+
+    def test_create_subnet_with_none_gateway_allocation_pool(self):
+        pass
+
+    def test_create_subnet_with_v6_allocation_pool(self):
+        pass
+
+    def test_create_subnet_with_large_allocation_pool(self):
+        pass
+
+    def test_create_subnet_multiple_allocation_pools(self):
+        pass
+
+    def test_create_subnet_with_dhcp_disabled(self):
+        pass
+
+    def test_create_subnet_default_gw_conflict_allocation_pool_returns_409(
+            self):
+        pass
+
+    def test_create_subnet_gateway_in_allocation_pool_returns_409(self):
+        pass
+
+    def test_create_subnet_overlapping_allocation_pools_returns_409(self):
+        pass
+
+    def test_create_subnet_invalid_allocation_pool_returns_400(self):
+        pass
+
+    def test_create_subnet_out_of_range_allocation_pool_returns_400(self):
+        pass
+
+    def test_create_subnet_shared_returns_400(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv6_cidrv4(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv4_cidrv6(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv4_gatewayv6(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv6_gatewayv4(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv6_dns_v4(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv4_hostroute_dst_v6(self):
+        pass
+
+    def test_create_subnet_inconsistent_ipv4_hostroute_np_v6(self):
+        pass
+
+    def test_create_subnet_gw_bcast_force_on_returns_400(self):
+        pass
+
+    def test_update_subnet(self):
+        pass
+
+    def test_update_subnet_shared_returns_400(self):
+        pass
+
+    def test_update_subnet_inconsistent_ipv4_gatewayv6(self):
+        pass
+
+    def test_update_subnet_inconsistent_ipv6_gatewayv4(self):
+        pass
+
+    def test_update_subnet_inconsistent_ipv4_dns_v6(self):
+        pass
+
+    def test_update_subnet_inconsistent_ipv6_hostroute_dst_v4(self):
+        pass
+
+    def test_update_subnet_inconsistent_ipv6_hostroute_np_v4(self):
+        pass
+
+    def test_show_subnet(self):
+        pass
+
+    def test_list_subnets(self):
+        pass
+
+    def test_list_subnets_shared(self):
+        pass
+
+    def test_list_subnets_with_parameter(self):
+        pass
+
+    def test_invalid_ip_version(self):
+        pass
+
+    def test_invalid_subnet(self):
+        pass
+
+    def test_invalid_ip_address(self):
+        pass
+
+    def test_invalid_uuid(self):
+        pass
+
+    def test_create_subnet_with_one_dns(self):
+        pass
+
+    def test_create_subnet_with_two_dns(self):
+        pass
+
+    def test_create_subnet_with_too_many_dns(self):
+        pass
+
+    def test_create_subnet_with_one_host_route(self):
+        pass
+
+    def test_create_subnet_with_two_host_routes(self):
+        pass
+
+    def test_create_subnet_with_too_many_routes(self):
+        pass
+
+    def test_update_subnet_dns(self):
+        pass
+
+    def test_update_subnet_dns_to_None(self):
+        pass
+
+    def test_update_subnet_dns_with_too_many_entries(self):
+        pass
+
+    def test_update_subnet_route(self):
+        pass
+
+    def test_update_subnet_route_to_None(self):
+        pass
+
+    def test_update_subnet_route_with_too_many_entries(self):
+        pass
+
+    def test_delete_subnet_with_dns(self):
+        pass
+
+    def test_delete_subnet_with_route(self):
+        pass
+
+    def test_delete_subnet_with_dns_and_route(self):
+        pass
+
+    def test_list_subnets_with_pagination_emulated(self):
+        pass
+
+    def test_list_subnets_with_pagination_reverse_emulated(self):
+        pass
+
+    def test_list_subnets_with_sort_emulated(self):
+        pass
+
+    def test_validate_subnet_host_routes_exhausted(self):
+        pass
+
+    def test_validate_subnet_dns_nameservers_exhausted(self):
+        pass
+
+
+class TestContrailPortsV2(test_plugin.TestPortsV2,
+                          JVContrailPluginTestCase):
+
+    def test_create_port_json(self):
+        pass
+
+    def test_create_port_bad_tenant(self):
+        pass
+
+    def test_create_port_public_network(self):
+        pass
+
+    def test_create_port_public_network_with_ip(self):
+        pass
+
+    def test_create_ports_bulk_native(self):
+        pass
+
+    def test_create_ports_bulk_emulated(self):
+        pass
+
+    def test_create_ports_bulk_wrong_input(self):
+        pass
+
+    def test_create_ports_bulk_emulated_plugin_failure(self):
+        pass
+
+    def test_create_ports_bulk_native_plugin_failure(self):
+        pass
+
+    def test_list_ports(self):
+        pass
+
+    def test_list_ports_filtered_by_fixed_ip(self):
+        pass
+
+    def test_list_ports_public_network(self):
+        pass
+
+    def test_show_port(self):
+        pass
+
+    def test_delete_port(self):
+        pass
+
+    def test_delete_port_public_network(self):
+        pass
+
+    def test_update_port(self):
+        pass
+
+    def test_update_device_id_null(self):
+        pass
+
+    def test_delete_network_if_port_exists(self):
+        pass
+
+    def test_delete_network_port_exists_owned_by_network(self):
+        pass
+
+    def test_update_port_delete_ip(self):
+        pass
+
+    def test_no_more_port_exception(self):
+        pass
+
+    def test_update_port_update_ip(self):
+        pass
+
+    def test_update_port_update_ip_address_only(self):
+        pass
+
+    def test_update_port_update_ips(self):
+        pass
+
+    def test_update_port_add_additional_ip(self):
+        pass
+
+    def test_requested_duplicate_mac(self):
+        pass
+
+    def test_mac_generation(self):
+        pass
+
+    def test_mac_generation_4octet(self):
+        pass
+
+    def test_bad_mac_format(self):
+        pass
+
+    def test_mac_exhaustion(self):
+        pass
+
+    def test_requested_duplicate_ip(self):
+        pass
+
+    def test_requested_subnet_delete(self):
+        pass
+
+    def test_requested_subnet_id(self):
+        pass
+
+    def test_requested_subnet_id_not_on_network(self):
+        pass
+
+    def test_overlapping_subnets(self):
+        pass
+
+    def test_requested_subnet_id_v4_and_v6(self):
+        pass
+
+    def test_range_allocation(self):
+        pass
+
+    def test_requested_invalid_fixed_ips(self):
+        pass
+
+    def test_invalid_ip(self):
+        pass
+
+    def test_requested_split(self):
+        pass
+
+    def test_duplicate_ips(self):
+        pass
+
+    def test_fixed_ip_invalid_subnet_id(self):
+        pass
+
+    def test_fixed_ip_invalid_ip(self):
+        pass
+
+    def test_requested_ips_only(self):
+        pass
+
+    def test_recycling(self):
+        pass
+
+    def test_invalid_admin_state(self):
+        pass
+
+    def test_invalid_mac_address(self):
+        pass
+
+    def test_default_allocation_expiration(self):
+        pass
+
+    def test_update_fixed_ip_lease_expiration(self):
+        pass
+
+    def test_port_delete_holds_ip(self):
+        pass
+
+    def test_update_fixed_ip_lease_expiration_invalid_address(self):
+        pass
+
+    def test_hold_ip_address(self):
+        pass
+
+    def test_recycle_held_ip_address(self):
+        pass
+
+    def test_recycle_expired_previously_run_within_context(self):
+        pass
+
+    def test_update_port_not_admin(self):
+        pass
+
+    def test_list_ports_with_pagination_emulated(self):
+        pass
+
+    def test_list_ports_with_pagination_reverse_emulated(self):
+        pass
+
+    def test_list_ports_with_sort_emulated(self):
+        pass
+
+    def test_max_fixed_ips_exceeded(self):
+        pass
+
+    def test_update_max_fixed_ips_exceeded(self):
+        pass
+
+    def test_recycle_ip_address_without_allocation_pool(self):
+        pass
diff --git setup.cfg setup.cfg
index af52a4d..27ef0ce 100644
--- setup.cfg
+++ setup.cfg
@@ -61,6 +61,7 @@ data_files =
     etc/neutron/plugins/openvswitch = etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini
     etc/neutron/plugins/plumgrid = etc/neutron/plugins/plumgrid/plumgrid.ini
     etc/neutron/plugins/ryu = etc/neutron/plugins/ryu/ryu.ini
+    etc/neutron/plugins/juniper/contrail/ContrailPlugin = etc/neutron/plugins/juniper/contrail/ContrailPlugin.ini
 scripts =
     bin/quantum-rootwrap
     bin/neutron-rootwrap
